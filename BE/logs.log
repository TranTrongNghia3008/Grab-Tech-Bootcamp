2025-05-03 15:12:46,696:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 15:12:46,696:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 15:12:46,696:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 15:12:46,696:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:43:29,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:43:29,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:43:29,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:43:29,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:46:37,508:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:46:37,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:46:37,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:46:37,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:48:16,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:48:16,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:48:16,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:48:16,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:50:15,390:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:50:15,390:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:50:15,390:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:50:15,390:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:50:30,495:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:50:30,495:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:50:30,495:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:50:30,495:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:58:20,838:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:58:20,838:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:58:20,838:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 16:58:20,838:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:01:11,352:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:01:11,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:01:11,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:01:11,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:02:13,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:02:13,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:02:13,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:02:13,868:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:02:28,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:02:28,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:02:28,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:02:28,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:02:42,904:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:02:42,904:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:02:42,904:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:02:42,904:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:02:54,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:02:54,202:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:02:54,202:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-03 17:02:54,202:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:03:25,183:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:03:25,183:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:03:25,183:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:03:25,183:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:08:04,078:INFO:PyCaret ClassificationExperiment
2025-05-04 00:08:04,078:INFO:Logging name: automl_bigdata_exp
2025-05-04 00:08:04,078:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-04 00:08:04,079:INFO:version 3.3.2
2025-05-04 00:08:04,079:INFO:Initializing setup()
2025-05-04 00:08:04,079:INFO:self.USI: 73d1
2025-05-04 00:08:04,079:INFO:self._variable_keys: {'idx', '_ml_usecase', 'gpu_param', 'html_param', 'target_param', 'X_test', 'y', 'seed', 'logging_param', 'pipeline', 'memory', 'fold_generator', 'log_plots_param', 'y_train', 'exp_id', 'y_test', 'X_train', 'fix_imbalance', 'fold_groups_param', 'gpu_n_jobs_param', 'n_jobs_param', '_available_plots', 'exp_name_log', 'X', 'data', 'USI', 'fold_shuffle_param', 'is_multiclass'}
2025-05-04 00:08:04,079:INFO:Checking environment
2025-05-04 00:08:04,079:INFO:python_version: 3.10.11
2025-05-04 00:08:04,079:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2025-05-04 00:08:04,079:INFO:machine: AMD64
2025-05-04 00:08:04,113:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-04 00:08:04,113:INFO:Memory: svmem(total=8425017344, available=628658176, percent=92.5, used=7796359168, free=628658176)
2025-05-04 00:08:04,113:INFO:Physical Core: 4
2025-05-04 00:08:04,113:INFO:Logical Core: 8
2025-05-04 00:08:04,113:INFO:Checking libraries
2025-05-04 00:08:04,113:INFO:System:
2025-05-04 00:08:04,113:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2025-05-04 00:08:04,113:INFO:executable: c:\LKN\venv\Scripts\python.exe
2025-05-04 00:08:04,113:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-04 00:08:04,113:INFO:PyCaret required dependencies:
2025-05-04 00:08:04,356:INFO:                 pip: 23.0.1
2025-05-04 00:08:04,356:INFO:          setuptools: 65.5.0
2025-05-04 00:08:04,356:INFO:             pycaret: 3.3.2
2025-05-04 00:08:04,356:INFO:             IPython: 8.36.0
2025-05-04 00:08:04,356:INFO:          ipywidgets: 8.1.6
2025-05-04 00:08:04,356:INFO:                tqdm: 4.67.1
2025-05-04 00:08:04,356:INFO:               numpy: 1.26.4
2025-05-04 00:08:04,356:INFO:              pandas: 1.5.3
2025-05-04 00:08:04,356:INFO:              jinja2: 3.1.6
2025-05-04 00:08:04,356:INFO:               scipy: 1.11.4
2025-05-04 00:08:04,356:INFO:              joblib: 1.3.2
2025-05-04 00:08:04,356:INFO:             sklearn: 1.4.2
2025-05-04 00:08:04,356:INFO:                pyod: 2.0.4
2025-05-04 00:08:04,356:INFO:            imblearn: 0.13.0
2025-05-04 00:08:04,356:INFO:   category_encoders: 2.7.0
2025-05-04 00:08:04,356:INFO:            lightgbm: 4.6.0
2025-05-04 00:08:04,356:INFO:               numba: 0.61.0
2025-05-04 00:08:04,356:INFO:            requests: 2.32.3
2025-05-04 00:08:04,356:INFO:          matplotlib: 3.7.5
2025-05-04 00:08:04,356:INFO:          scikitplot: 0.3.7
2025-05-04 00:08:04,356:INFO:         yellowbrick: 1.5
2025-05-04 00:08:04,356:INFO:              plotly: 5.24.1
2025-05-04 00:08:04,356:INFO:    plotly-resampler: Not installed
2025-05-04 00:08:04,356:INFO:             kaleido: 0.2.1
2025-05-04 00:08:04,356:INFO:           schemdraw: 0.15
2025-05-04 00:08:04,356:INFO:         statsmodels: 0.14.4
2025-05-04 00:08:04,356:INFO:              sktime: 0.26.0
2025-05-04 00:08:04,356:INFO:               tbats: 1.1.3
2025-05-04 00:08:04,356:INFO:            pmdarima: 2.0.4
2025-05-04 00:08:04,356:INFO:              psutil: 7.0.0
2025-05-04 00:08:04,356:INFO:          markupsafe: 3.0.2
2025-05-04 00:08:04,356:INFO:             pickle5: Not installed
2025-05-04 00:08:04,356:INFO:         cloudpickle: 2.2.1
2025-05-04 00:08:04,356:INFO:         deprecation: 2.1.0
2025-05-04 00:08:04,356:INFO:              xxhash: 3.5.0
2025-05-04 00:08:04,356:INFO:           wurlitzer: Not installed
2025-05-04 00:08:04,356:INFO:PyCaret optional dependencies:
2025-05-04 00:08:04,371:INFO:                shap: 0.47.2
2025-05-04 00:08:04,371:INFO:           interpret: Not installed
2025-05-04 00:08:04,371:INFO:                umap: Not installed
2025-05-04 00:08:04,371:INFO:     ydata_profiling: 4.16.1
2025-05-04 00:08:04,371:INFO:  explainerdashboard: Not installed
2025-05-04 00:08:04,371:INFO:             autoviz: Not installed
2025-05-04 00:08:04,371:INFO:           fairlearn: Not installed
2025-05-04 00:08:04,371:INFO:          deepchecks: Not installed
2025-05-04 00:08:04,371:INFO:             xgboost: Not installed
2025-05-04 00:08:04,371:INFO:            catboost: Not installed
2025-05-04 00:08:04,371:INFO:              kmodes: Not installed
2025-05-04 00:08:04,371:INFO:             mlxtend: Not installed
2025-05-04 00:08:04,371:INFO:       statsforecast: Not installed
2025-05-04 00:08:04,371:INFO:        tune_sklearn: Not installed
2025-05-04 00:08:04,371:INFO:                 ray: Not installed
2025-05-04 00:08:04,371:INFO:            hyperopt: Not installed
2025-05-04 00:08:04,371:INFO:              optuna: 4.3.0
2025-05-04 00:08:04,371:INFO:               skopt: Not installed
2025-05-04 00:08:04,371:INFO:              mlflow: 2.22.0
2025-05-04 00:08:04,371:INFO:              gradio: Not installed
2025-05-04 00:08:04,371:INFO:             fastapi: 0.115.12
2025-05-04 00:08:04,371:INFO:             uvicorn: 0.34.2
2025-05-04 00:08:04,371:INFO:              m2cgen: Not installed
2025-05-04 00:08:04,371:INFO:           evidently: 0.7.3
2025-05-04 00:08:04,371:INFO:               fugue: Not installed
2025-05-04 00:08:04,371:INFO:           streamlit: Not installed
2025-05-04 00:08:04,371:INFO:             prophet: Not installed
2025-05-04 00:08:04,371:INFO:None
2025-05-04 00:08:04,371:INFO:Set up data.
2025-05-04 00:08:04,375:INFO:Set up folding strategy.
2025-05-04 00:08:04,375:INFO:Set up train/test split.
2025-05-04 00:08:04,387:INFO:Set up index.
2025-05-04 00:08:04,387:INFO:Assigning column types.
2025-05-04 00:08:04,387:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-04 00:08:04,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-04 00:08:04,449:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-04 00:08:04,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:08:04,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:08:04,545:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-04 00:08:04,545:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-04 00:08:04,593:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:08:04,593:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:08:04,593:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-04 00:08:04,639:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-04 00:08:04,671:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:08:04,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:08:04,718:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-04 00:08:04,750:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:08:04,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:08:04,750:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-04 00:08:04,829:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:08:04,829:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:08:04,908:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:08:04,908:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:08:04,926:INFO:Preparing preprocessing pipeline...
2025-05-04 00:08:04,926:INFO:Set up simple imputation.
2025-05-04 00:08:04,926:INFO:Set up encoding of ordinal features.
2025-05-04 00:08:04,926:INFO:Set up encoding of categorical features.
2025-05-04 00:08:04,926:INFO:Set up column name cleaning.
2025-05-04 00:08:05,038:INFO:Finished creating preprocessing pipeline.
2025-05-04 00:08:05,066:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-05-04 00:08:05,066:INFO:Creating final display dataframe.
2025-05-04 00:08:05,255:INFO:Setup _display_container:                     Description               Value
0                    Session id                   1
1                        Target         Dropped_out
2                   Target type              Binary
3           Original data shape           (249, 17)
4        Transformed data shape            (249, 6)
5   Transformed train set shape            (174, 6)
6    Transformed test set shape             (75, 6)
7               Ignore features                  11
8              Numeric features                   4
9          Categorical features                   1
10     Rows with missing values               38.2%
11                   Preprocess                True
12              Imputation type              simple
13           Numeric imputation                mean
14       Categorical imputation                mode
15     Maximum one-hot encoding                  25
16              Encoding method                None
17               Fold Generator     StratifiedKFold
18                  Fold Number                   5
19                     CPU Jobs                  -1
20                      Use GPU               False
21               Log Experiment        MlflowLogger
22              Experiment Name  automl_bigdata_exp
23                          USI                73d1
2025-05-04 00:08:05,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:08:05,335:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:08:05,430:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:08:05,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:08:05,430:INFO:Logging experiment in loggers
2025-05-04 00:08:05,525:INFO:SubProcess save_model() called ==================================
2025-05-04 00:08:05,573:INFO:Initializing save_model()
2025-05-04 00:08:05,573:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\nkluo\AppData\Local\Temp\tmpvoijt11d\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-04 00:08:05,573:INFO:Adding model into prep_pipe
2025-05-04 00:08:05,573:WARNING:Only Model saved as it was a pipeline.
2025-05-04 00:08:05,578:INFO:C:\Users\nkluo\AppData\Local\Temp\tmpvoijt11d\Transformation Pipeline.pkl saved in current working directory
2025-05-04 00:08:05,604:INFO:Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-05-04 00:08:05,604:INFO:save_model() successfully completed......................................
2025-05-04 00:08:05,873:INFO:SubProcess save_model() end ==================================
2025-05-04 00:08:05,927:INFO:setup() successfully completed in 1.4s...............
2025-05-04 00:08:06,031:INFO:Initializing compare_models()
2025-05-04 00:08:06,031:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, include=['lr', 'ridge', 'lightgbm', 'rf', 'et'], fold=5, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=False, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, 'include': ['lr', 'ridge', 'lightgbm', 'rf', 'et'], 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': False, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-05-04 00:08:06,031:INFO:Checking exceptions
2025-05-04 00:08:06,031:INFO:Preparing display monitor
2025-05-04 00:08:06,031:INFO:Initializing Logistic Regression
2025-05-04 00:08:06,031:INFO:Total runtime is 0.0 minutes
2025-05-04 00:08:06,031:INFO:SubProcess create_model() called ==================================
2025-05-04 00:08:06,031:INFO:Initializing create_model()
2025-05-04 00:08:06,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B42B76C100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:08:06,031:INFO:Checking exceptions
2025-05-04 00:08:06,031:INFO:Importing libraries
2025-05-04 00:08:06,031:INFO:Copying training dataset
2025-05-04 00:08:06,031:INFO:Defining folds
2025-05-04 00:08:06,031:INFO:Declaring metric variables
2025-05-04 00:08:06,031:INFO:Importing untrained model
2025-05-04 00:08:06,031:INFO:Logistic Regression Imported successfully
2025-05-04 00:08:06,031:INFO:Starting cross validation
2025-05-04 00:08:06,051:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:08:15,031:INFO:Calculating mean and std
2025-05-04 00:08:15,033:INFO:Creating metrics dataframe
2025-05-04 00:08:15,045:INFO:Uploading results into container
2025-05-04 00:08:15,049:INFO:Uploading model into container now
2025-05-04 00:08:15,050:INFO:_master_model_container: 1
2025-05-04 00:08:15,052:INFO:_display_container: 2
2025-05-04 00:08:15,052:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-04 00:08:15,052:INFO:create_model() successfully completed......................................
2025-05-04 00:08:15,317:INFO:SubProcess create_model() end ==================================
2025-05-04 00:08:15,317:INFO:Creating metrics dataframe
2025-05-04 00:08:15,329:INFO:Initializing Ridge Classifier
2025-05-04 00:08:15,329:INFO:Total runtime is 0.15495961507161457 minutes
2025-05-04 00:08:15,329:INFO:SubProcess create_model() called ==================================
2025-05-04 00:08:15,329:INFO:Initializing create_model()
2025-05-04 00:08:15,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B42B76C100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:08:15,329:INFO:Checking exceptions
2025-05-04 00:08:15,329:INFO:Importing libraries
2025-05-04 00:08:15,329:INFO:Copying training dataset
2025-05-04 00:08:15,333:INFO:Defining folds
2025-05-04 00:08:15,333:INFO:Declaring metric variables
2025-05-04 00:08:15,333:INFO:Importing untrained model
2025-05-04 00:08:15,333:INFO:Ridge Classifier Imported successfully
2025-05-04 00:08:15,333:INFO:Starting cross validation
2025-05-04 00:08:15,333:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:08:21,991:INFO:Calculating mean and std
2025-05-04 00:08:21,994:INFO:Creating metrics dataframe
2025-05-04 00:08:21,998:INFO:Uploading results into container
2025-05-04 00:08:22,007:INFO:Uploading model into container now
2025-05-04 00:08:22,009:INFO:_master_model_container: 2
2025-05-04 00:08:22,009:INFO:_display_container: 2
2025-05-04 00:08:22,009:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1, solver='auto',
                tol=0.0001)
2025-05-04 00:08:22,009:INFO:create_model() successfully completed......................................
2025-05-04 00:08:22,263:INFO:SubProcess create_model() end ==================================
2025-05-04 00:08:22,264:INFO:Creating metrics dataframe
2025-05-04 00:08:22,272:INFO:Initializing Light Gradient Boosting Machine
2025-05-04 00:08:22,273:INFO:Total runtime is 0.2706946531931559 minutes
2025-05-04 00:08:22,273:INFO:SubProcess create_model() called ==================================
2025-05-04 00:08:22,273:INFO:Initializing create_model()
2025-05-04 00:08:22,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B42B76C100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:08:22,273:INFO:Checking exceptions
2025-05-04 00:08:22,274:INFO:Importing libraries
2025-05-04 00:08:22,274:INFO:Copying training dataset
2025-05-04 00:08:22,276:INFO:Defining folds
2025-05-04 00:08:22,276:INFO:Declaring metric variables
2025-05-04 00:08:22,276:INFO:Importing untrained model
2025-05-04 00:08:22,276:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-04 00:08:22,276:INFO:Starting cross validation
2025-05-04 00:08:22,282:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:08:22,771:INFO:Calculating mean and std
2025-05-04 00:08:22,772:INFO:Creating metrics dataframe
2025-05-04 00:08:22,782:INFO:Uploading results into container
2025-05-04 00:08:22,783:INFO:Uploading model into container now
2025-05-04 00:08:22,784:INFO:_master_model_container: 3
2025-05-04 00:08:22,784:INFO:_display_container: 2
2025-05-04 00:08:22,786:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-04 00:08:22,786:INFO:create_model() successfully completed......................................
2025-05-04 00:08:23,007:INFO:SubProcess create_model() end ==================================
2025-05-04 00:08:23,008:INFO:Creating metrics dataframe
2025-05-04 00:08:23,014:INFO:Initializing Random Forest Classifier
2025-05-04 00:08:23,014:INFO:Total runtime is 0.2830495675404866 minutes
2025-05-04 00:08:23,015:INFO:SubProcess create_model() called ==================================
2025-05-04 00:08:23,015:INFO:Initializing create_model()
2025-05-04 00:08:23,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B42B76C100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:08:23,015:INFO:Checking exceptions
2025-05-04 00:08:23,015:INFO:Importing libraries
2025-05-04 00:08:23,015:INFO:Copying training dataset
2025-05-04 00:08:23,020:INFO:Defining folds
2025-05-04 00:08:23,020:INFO:Declaring metric variables
2025-05-04 00:08:23,020:INFO:Importing untrained model
2025-05-04 00:08:23,020:INFO:Random Forest Classifier Imported successfully
2025-05-04 00:08:23,021:INFO:Starting cross validation
2025-05-04 00:08:23,024:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:08:23,732:INFO:Calculating mean and std
2025-05-04 00:08:23,733:INFO:Creating metrics dataframe
2025-05-04 00:08:23,742:INFO:Uploading results into container
2025-05-04 00:08:23,743:INFO:Uploading model into container now
2025-05-04 00:08:23,744:INFO:_master_model_container: 4
2025-05-04 00:08:23,744:INFO:_display_container: 2
2025-05-04 00:08:23,745:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False)
2025-05-04 00:08:23,745:INFO:create_model() successfully completed......................................
2025-05-04 00:08:23,938:INFO:SubProcess create_model() end ==================================
2025-05-04 00:08:23,938:INFO:Creating metrics dataframe
2025-05-04 00:08:23,953:INFO:Initializing Extra Trees Classifier
2025-05-04 00:08:23,953:INFO:Total runtime is 0.2987012942632039 minutes
2025-05-04 00:08:23,953:INFO:SubProcess create_model() called ==================================
2025-05-04 00:08:23,953:INFO:Initializing create_model()
2025-05-04 00:08:23,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B42B76C100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:08:23,953:INFO:Checking exceptions
2025-05-04 00:08:23,953:INFO:Importing libraries
2025-05-04 00:08:23,953:INFO:Copying training dataset
2025-05-04 00:08:23,953:INFO:Defining folds
2025-05-04 00:08:23,953:INFO:Declaring metric variables
2025-05-04 00:08:23,953:INFO:Importing untrained model
2025-05-04 00:08:23,953:INFO:Extra Trees Classifier Imported successfully
2025-05-04 00:08:23,953:INFO:Starting cross validation
2025-05-04 00:08:23,953:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:08:24,466:INFO:Calculating mean and std
2025-05-04 00:08:24,466:INFO:Creating metrics dataframe
2025-05-04 00:08:24,466:INFO:Uploading results into container
2025-05-04 00:08:24,466:INFO:Uploading model into container now
2025-05-04 00:08:24,466:INFO:_master_model_container: 5
2025-05-04 00:08:24,466:INFO:_display_container: 2
2025-05-04 00:08:24,466:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1, verbose=0,
                     warm_start=False)
2025-05-04 00:08:24,466:INFO:create_model() successfully completed......................................
2025-05-04 00:08:24,643:INFO:SubProcess create_model() end ==================================
2025-05-04 00:08:24,643:INFO:Creating metrics dataframe
2025-05-04 00:08:24,645:INFO:Initializing create_model()
2025-05-04 00:08:24,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:08:24,655:INFO:Checking exceptions
2025-05-04 00:08:24,657:INFO:Importing libraries
2025-05-04 00:08:24,657:INFO:Copying training dataset
2025-05-04 00:08:24,662:INFO:Defining folds
2025-05-04 00:08:24,662:INFO:Declaring metric variables
2025-05-04 00:08:24,662:INFO:Importing untrained model
2025-05-04 00:08:24,662:INFO:Declaring custom model
2025-05-04 00:08:24,664:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-04 00:08:24,664:INFO:Cross validation set to False
2025-05-04 00:08:24,664:INFO:Fitting Model
2025-05-04 00:08:24,742:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-05-04 00:08:24,743:INFO:[LightGBM] [Info] Number of positive: 118, number of negative: 56
2025-05-04 00:08:24,745:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000202 seconds.
2025-05-04 00:08:24,745:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-04 00:08:24,745:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-04 00:08:24,746:INFO:[LightGBM] [Info] Total Bins 8
2025-05-04 00:08:24,747:INFO:[LightGBM] [Info] Number of data points in the train set: 174, number of used features: 4
2025-05-04 00:08:24,747:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.678161 -> initscore=0.745333
2025-05-04 00:08:24,748:INFO:[LightGBM] [Info] Start training from score 0.745333
2025-05-04 00:08:24,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:24,803:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-04 00:08:24,804:INFO:create_model() successfully completed......................................
2025-05-04 00:08:25,024:INFO:Creating Dashboard logs
2025-05-04 00:08:25,024:INFO:Model: Light Gradient Boosting Machine
2025-05-04 00:08:25,058:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 1, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-05-04 00:08:25,224:INFO:Initializing predict_model()
2025-05-04 00:08:25,224:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B42B51E200>)
2025-05-04 00:08:25,225:INFO:Checking exceptions
2025-05-04 00:08:25,225:INFO:Preloading libraries
2025-05-04 00:08:25,619:WARNING:c:\LKN\venv\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2025-05-04 00:08:25,942:INFO:Creating Dashboard logs
2025-05-04 00:08:25,943:INFO:Model: Extra Trees Classifier
2025-05-04 00:08:25,971:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}
2025-05-04 00:08:26,344:INFO:Creating Dashboard logs
2025-05-04 00:08:26,345:INFO:Model: Random Forest Classifier
2025-05-04 00:08:26,372:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}
2025-05-04 00:08:26,754:INFO:Creating Dashboard logs
2025-05-04 00:08:26,755:INFO:Model: Ridge Classifier
2025-05-04 00:08:26,783:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 1, 'solver': 'auto', 'tol': 0.0001}
2025-05-04 00:08:27,171:INFO:Creating Dashboard logs
2025-05-04 00:08:27,171:INFO:Model: Logistic Regression
2025-05-04 00:08:27,196:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 1, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-05-04 00:08:27,627:INFO:_master_model_container: 5
2025-05-04 00:08:27,627:INFO:_display_container: 2
2025-05-04 00:08:27,628:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-04 00:08:27,628:INFO:compare_models() successfully completed......................................
2025-05-04 00:08:27,721:INFO:Initializing create_model()
2025-05-04 00:08:27,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, estimator=lr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:08:27,721:INFO:Checking exceptions
2025-05-04 00:08:27,721:INFO:Importing libraries
2025-05-04 00:08:27,721:INFO:Copying training dataset
2025-05-04 00:08:27,738:INFO:Defining folds
2025-05-04 00:08:27,738:INFO:Declaring metric variables
2025-05-04 00:08:27,738:INFO:Importing untrained model
2025-05-04 00:08:27,738:INFO:Logistic Regression Imported successfully
2025-05-04 00:08:27,738:INFO:Starting cross validation
2025-05-04 00:08:27,738:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:08:27,892:INFO:Calculating mean and std
2025-05-04 00:08:27,892:INFO:Creating metrics dataframe
2025-05-04 00:08:27,892:INFO:Finalizing model
2025-05-04 00:08:27,927:INFO:Creating Dashboard logs
2025-05-04 00:08:27,937:INFO:Model: Logistic Regression
2025-05-04 00:08:27,958:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 1, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-05-04 00:08:28,158:INFO:Initializing predict_model()
2025-05-04 00:08:28,159:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B4230FE680>)
2025-05-04 00:08:28,159:INFO:Checking exceptions
2025-05-04 00:08:28,159:INFO:Preloading libraries
2025-05-04 00:08:28,751:INFO:Uploading results into container
2025-05-04 00:08:28,751:INFO:Uploading model into container now
2025-05-04 00:08:28,752:INFO:_master_model_container: 6
2025-05-04 00:08:28,752:INFO:_display_container: 3
2025-05-04 00:08:28,752:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-04 00:08:28,752:INFO:create_model() successfully completed......................................
2025-05-04 00:08:28,994:INFO:Initializing plot_model()
2025-05-04 00:08:28,994:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, system=True)
2025-05-04 00:08:28,994:INFO:Checking exceptions
2025-05-04 00:08:28,997:INFO:Preloading libraries
2025-05-04 00:08:28,997:INFO:Copying training dataset
2025-05-04 00:08:28,997:INFO:Plot type: feature
2025-05-04 00:08:29,260:WARNING:c:\LKN\venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1845: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  plt.figure(figsize=(8, 5 * (n // 10)), dpi=_base_dpi * scale)

2025-05-04 00:08:31,261:INFO:Saving 'Feature Importance.png'
2025-05-04 00:08:31,485:INFO:Visual Rendered Successfully
2025-05-04 00:08:31,710:INFO:plot_model() successfully completed......................................
2025-05-04 00:08:31,843:INFO:Initializing create_model()
2025-05-04 00:08:31,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, estimator=ridge, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:08:31,844:INFO:Checking exceptions
2025-05-04 00:08:31,845:INFO:Importing libraries
2025-05-04 00:08:31,845:INFO:Copying training dataset
2025-05-04 00:08:31,850:INFO:Defining folds
2025-05-04 00:08:31,850:INFO:Declaring metric variables
2025-05-04 00:08:31,851:INFO:Importing untrained model
2025-05-04 00:08:31,851:INFO:Ridge Classifier Imported successfully
2025-05-04 00:08:31,851:INFO:Starting cross validation
2025-05-04 00:08:31,856:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:08:32,069:INFO:Calculating mean and std
2025-05-04 00:08:32,071:INFO:Creating metrics dataframe
2025-05-04 00:08:32,072:INFO:Finalizing model
2025-05-04 00:08:32,104:INFO:Creating Dashboard logs
2025-05-04 00:08:32,104:INFO:Model: Ridge Classifier
2025-05-04 00:08:32,136:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 1, 'solver': 'auto', 'tol': 0.0001}
2025-05-04 00:08:32,289:INFO:Initializing predict_model()
2025-05-04 00:08:32,289:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1, solver='auto',
                tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B42B8F4AF0>)
2025-05-04 00:08:32,289:INFO:Checking exceptions
2025-05-04 00:08:32,289:INFO:Preloading libraries
2025-05-04 00:08:32,835:INFO:Uploading results into container
2025-05-04 00:08:32,836:INFO:Uploading model into container now
2025-05-04 00:08:32,836:INFO:_master_model_container: 7
2025-05-04 00:08:32,836:INFO:_display_container: 4
2025-05-04 00:08:32,836:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1, solver='auto',
                tol=0.0001)
2025-05-04 00:08:32,836:INFO:create_model() successfully completed......................................
2025-05-04 00:08:33,073:INFO:Initializing plot_model()
2025-05-04 00:08:33,073:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, system=True)
2025-05-04 00:08:33,073:INFO:Checking exceptions
2025-05-04 00:08:33,074:INFO:Preloading libraries
2025-05-04 00:08:33,074:INFO:Copying training dataset
2025-05-04 00:08:33,074:INFO:Plot type: feature
2025-05-04 00:08:33,199:WARNING:c:\LKN\venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1845: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  plt.figure(figsize=(8, 5 * (n // 10)), dpi=_base_dpi * scale)

2025-05-04 00:08:33,374:INFO:Saving 'Feature Importance.png'
2025-05-04 00:08:33,507:INFO:Visual Rendered Successfully
2025-05-04 00:08:33,688:INFO:plot_model() successfully completed......................................
2025-05-04 00:08:33,814:INFO:Initializing create_model()
2025-05-04 00:08:33,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:08:33,814:INFO:Checking exceptions
2025-05-04 00:08:33,815:INFO:Importing libraries
2025-05-04 00:08:33,815:INFO:Copying training dataset
2025-05-04 00:08:33,825:INFO:Defining folds
2025-05-04 00:08:33,825:INFO:Declaring metric variables
2025-05-04 00:08:33,826:INFO:Importing untrained model
2025-05-04 00:08:33,827:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-04 00:08:33,828:INFO:Starting cross validation
2025-05-04 00:08:33,829:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:08:34,449:INFO:Calculating mean and std
2025-05-04 00:08:34,449:INFO:Creating metrics dataframe
2025-05-04 00:08:34,457:INFO:Finalizing model
2025-05-04 00:08:34,531:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-05-04 00:08:34,531:INFO:[LightGBM] [Info] Number of positive: 118, number of negative: 56
2025-05-04 00:08:34,533:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000163 seconds.
2025-05-04 00:08:34,533:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-04 00:08:34,533:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-04 00:08:34,533:INFO:[LightGBM] [Info] Total Bins 8
2025-05-04 00:08:34,533:INFO:[LightGBM] [Info] Number of data points in the train set: 174, number of used features: 4
2025-05-04 00:08:34,533:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.678161 -> initscore=0.745333
2025-05-04 00:08:34,535:INFO:[LightGBM] [Info] Start training from score 0.745333
2025-05-04 00:08:34,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:08:34,646:INFO:Creating Dashboard logs
2025-05-04 00:08:34,647:INFO:Model: Light Gradient Boosting Machine
2025-05-04 00:08:34,719:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 1, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-05-04 00:08:34,910:INFO:Initializing predict_model()
2025-05-04 00:08:34,912:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B42B51E290>)
2025-05-04 00:08:34,912:INFO:Checking exceptions
2025-05-04 00:08:34,912:INFO:Preloading libraries
2025-05-04 00:08:35,656:INFO:Uploading results into container
2025-05-04 00:08:35,656:INFO:Uploading model into container now
2025-05-04 00:08:35,656:INFO:_master_model_container: 8
2025-05-04 00:08:35,656:INFO:_display_container: 5
2025-05-04 00:08:35,660:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-04 00:08:35,660:INFO:create_model() successfully completed......................................
2025-05-04 00:08:35,888:INFO:Initializing plot_model()
2025-05-04 00:08:35,888:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, system=True)
2025-05-04 00:08:35,888:INFO:Checking exceptions
2025-05-04 00:08:35,888:INFO:Preloading libraries
2025-05-04 00:08:35,897:INFO:Copying training dataset
2025-05-04 00:08:35,897:INFO:Plot type: feature
2025-05-04 00:08:35,899:WARNING:No coef_ found. Trying feature_importances_
2025-05-04 00:08:35,997:WARNING:c:\LKN\venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1845: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  plt.figure(figsize=(8, 5 * (n // 10)), dpi=_base_dpi * scale)

2025-05-04 00:08:36,162:INFO:Saving 'Feature Importance.png'
2025-05-04 00:08:36,319:INFO:Visual Rendered Successfully
2025-05-04 00:08:36,523:INFO:plot_model() successfully completed......................................
2025-05-04 00:08:36,683:INFO:Initializing create_model()
2025-05-04 00:08:36,683:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:08:36,683:INFO:Checking exceptions
2025-05-04 00:08:36,684:INFO:Importing libraries
2025-05-04 00:08:36,685:INFO:Copying training dataset
2025-05-04 00:08:36,685:INFO:Defining folds
2025-05-04 00:08:36,685:INFO:Declaring metric variables
2025-05-04 00:08:36,685:INFO:Importing untrained model
2025-05-04 00:08:36,685:INFO:Random Forest Classifier Imported successfully
2025-05-04 00:08:36,685:INFO:Starting cross validation
2025-05-04 00:08:36,685:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:08:37,572:INFO:Calculating mean and std
2025-05-04 00:08:37,572:INFO:Creating metrics dataframe
2025-05-04 00:08:37,575:INFO:Finalizing model
2025-05-04 00:08:38,074:INFO:Creating Dashboard logs
2025-05-04 00:08:38,077:INFO:Model: Random Forest Classifier
2025-05-04 00:08:38,150:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}
2025-05-04 00:08:38,492:INFO:Initializing predict_model()
2025-05-04 00:08:38,492:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B42B6F72E0>)
2025-05-04 00:08:38,492:INFO:Checking exceptions
2025-05-04 00:08:38,492:INFO:Preloading libraries
2025-05-04 00:08:39,623:INFO:Uploading results into container
2025-05-04 00:08:39,624:INFO:Uploading model into container now
2025-05-04 00:08:39,625:INFO:_master_model_container: 9
2025-05-04 00:08:39,625:INFO:_display_container: 6
2025-05-04 00:08:39,625:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False)
2025-05-04 00:08:39,626:INFO:create_model() successfully completed......................................
2025-05-04 00:08:40,019:INFO:Initializing plot_model()
2025-05-04 00:08:40,019:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, system=True)
2025-05-04 00:08:40,020:INFO:Checking exceptions
2025-05-04 00:08:40,090:INFO:Preloading libraries
2025-05-04 00:08:40,156:INFO:Copying training dataset
2025-05-04 00:08:40,157:INFO:Plot type: feature
2025-05-04 00:08:40,158:WARNING:No coef_ found. Trying feature_importances_
2025-05-04 00:08:40,339:WARNING:c:\LKN\venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1845: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  plt.figure(figsize=(8, 5 * (n // 10)), dpi=_base_dpi * scale)

2025-05-04 00:08:40,505:INFO:Saving 'Feature Importance.png'
2025-05-04 00:08:40,663:INFO:Visual Rendered Successfully
2025-05-04 00:08:40,840:INFO:plot_model() successfully completed......................................
2025-05-04 00:08:40,956:INFO:Initializing create_model()
2025-05-04 00:08:40,956:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, estimator=et, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:08:40,956:INFO:Checking exceptions
2025-05-04 00:08:40,961:INFO:Importing libraries
2025-05-04 00:08:40,961:INFO:Copying training dataset
2025-05-04 00:08:40,967:INFO:Defining folds
2025-05-04 00:08:40,968:INFO:Declaring metric variables
2025-05-04 00:08:40,968:INFO:Importing untrained model
2025-05-04 00:08:40,969:INFO:Extra Trees Classifier Imported successfully
2025-05-04 00:08:40,969:INFO:Starting cross validation
2025-05-04 00:08:40,970:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:08:41,586:INFO:Calculating mean and std
2025-05-04 00:08:41,588:INFO:Creating metrics dataframe
2025-05-04 00:08:41,596:INFO:Finalizing model
2025-05-04 00:08:41,791:INFO:Creating Dashboard logs
2025-05-04 00:08:41,791:INFO:Model: Extra Trees Classifier
2025-05-04 00:08:41,816:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}
2025-05-04 00:08:41,958:INFO:Initializing predict_model()
2025-05-04 00:08:41,959:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1, verbose=0,
                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B42B7A8CA0>)
2025-05-04 00:08:41,959:INFO:Checking exceptions
2025-05-04 00:08:41,959:INFO:Preloading libraries
2025-05-04 00:08:42,692:INFO:Uploading results into container
2025-05-04 00:08:42,692:INFO:Uploading model into container now
2025-05-04 00:08:42,693:INFO:_master_model_container: 10
2025-05-04 00:08:42,693:INFO:_display_container: 7
2025-05-04 00:08:42,693:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1, verbose=0,
                     warm_start=False)
2025-05-04 00:08:42,693:INFO:create_model() successfully completed......................................
2025-05-04 00:08:42,980:INFO:Initializing plot_model()
2025-05-04 00:08:42,980:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1, verbose=0,
                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B42B106EC0>, system=True)
2025-05-04 00:08:42,980:INFO:Checking exceptions
2025-05-04 00:08:43,020:INFO:Preloading libraries
2025-05-04 00:08:43,043:INFO:Copying training dataset
2025-05-04 00:08:43,043:INFO:Plot type: feature
2025-05-04 00:08:43,044:WARNING:No coef_ found. Trying feature_importances_
2025-05-04 00:08:43,121:WARNING:c:\LKN\venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1845: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  plt.figure(figsize=(8, 5 * (n // 10)), dpi=_base_dpi * scale)

2025-05-04 00:08:43,245:INFO:Saving 'Feature Importance.png'
2025-05-04 00:08:43,374:INFO:Visual Rendered Successfully
2025-05-04 00:08:43,552:INFO:plot_model() successfully completed......................................
2025-05-04 00:12:06,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:12:06,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:12:06,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:12:06,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:13:26,960:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:13:26,960:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:13:26,960:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:13:26,960:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:13:39,527:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:13:39,528:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:13:39,528:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:13:39,528:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:14:12,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:14:12,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:14:12,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:14:12,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:19:50,268:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:19:50,268:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:19:50,268:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:19:50,268:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:23:20,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:23:20,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:23:20,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:23:20,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:42:27,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:42:27,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:42:27,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:42:27,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:42:53,801:INFO:PyCaret ClassificationExperiment
2025-05-04 00:42:53,801:INFO:Logging name: automl_bigdata_exp
2025-05-04 00:42:53,801:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-04 00:42:53,801:INFO:version 3.3.2
2025-05-04 00:42:53,801:INFO:Initializing setup()
2025-05-04 00:42:53,801:INFO:self.USI: ca33
2025-05-04 00:42:53,801:INFO:self._variable_keys: {'y', 'X', '_available_plots', 'memory', 'idx', 'logging_param', 'y_train', '_ml_usecase', 'n_jobs_param', 'seed', 'gpu_param', 'X_test', 'target_param', 'exp_id', 'data', 'log_plots_param', 'fix_imbalance', 'exp_name_log', 'y_test', 'is_multiclass', 'fold_shuffle_param', 'X_train', 'fold_groups_param', 'fold_generator', 'pipeline', 'gpu_n_jobs_param', 'html_param', 'USI'}
2025-05-04 00:42:53,801:INFO:Checking environment
2025-05-04 00:42:53,802:INFO:python_version: 3.10.11
2025-05-04 00:42:53,802:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2025-05-04 00:42:53,802:INFO:machine: AMD64
2025-05-04 00:42:53,820:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-04 00:42:53,826:INFO:Memory: svmem(total=8425017344, available=1187119104, percent=85.9, used=7237898240, free=1187119104)
2025-05-04 00:42:53,827:INFO:Physical Core: 4
2025-05-04 00:42:53,827:INFO:Logical Core: 8
2025-05-04 00:42:53,827:INFO:Checking libraries
2025-05-04 00:42:53,827:INFO:System:
2025-05-04 00:42:53,827:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2025-05-04 00:42:53,827:INFO:executable: c:\LKN\venv\Scripts\python.exe
2025-05-04 00:42:53,827:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-04 00:42:53,827:INFO:PyCaret required dependencies:
2025-05-04 00:42:53,943:INFO:                 pip: 23.0.1
2025-05-04 00:42:53,943:INFO:          setuptools: 65.5.0
2025-05-04 00:42:53,943:INFO:             pycaret: 3.3.2
2025-05-04 00:42:53,943:INFO:             IPython: 8.36.0
2025-05-04 00:42:53,943:INFO:          ipywidgets: 8.1.6
2025-05-04 00:42:53,943:INFO:                tqdm: 4.67.1
2025-05-04 00:42:53,943:INFO:               numpy: 1.26.4
2025-05-04 00:42:53,943:INFO:              pandas: 1.5.3
2025-05-04 00:42:53,943:INFO:              jinja2: 3.1.6
2025-05-04 00:42:53,943:INFO:               scipy: 1.11.4
2025-05-04 00:42:53,943:INFO:              joblib: 1.3.2
2025-05-04 00:42:53,943:INFO:             sklearn: 1.4.2
2025-05-04 00:42:53,943:INFO:                pyod: 2.0.4
2025-05-04 00:42:53,943:INFO:            imblearn: 0.13.0
2025-05-04 00:42:53,943:INFO:   category_encoders: 2.7.0
2025-05-04 00:42:53,943:INFO:            lightgbm: 4.6.0
2025-05-04 00:42:53,943:INFO:               numba: 0.61.0
2025-05-04 00:42:53,943:INFO:            requests: 2.32.3
2025-05-04 00:42:53,943:INFO:          matplotlib: 3.7.5
2025-05-04 00:42:53,943:INFO:          scikitplot: 0.3.7
2025-05-04 00:42:53,943:INFO:         yellowbrick: 1.5
2025-05-04 00:42:53,943:INFO:              plotly: 5.24.1
2025-05-04 00:42:53,943:INFO:    plotly-resampler: Not installed
2025-05-04 00:42:53,943:INFO:             kaleido: 0.2.1
2025-05-04 00:42:53,943:INFO:           schemdraw: 0.15
2025-05-04 00:42:53,943:INFO:         statsmodels: 0.14.4
2025-05-04 00:42:53,943:INFO:              sktime: 0.26.0
2025-05-04 00:42:53,943:INFO:               tbats: 1.1.3
2025-05-04 00:42:53,943:INFO:            pmdarima: 2.0.4
2025-05-04 00:42:53,943:INFO:              psutil: 7.0.0
2025-05-04 00:42:53,943:INFO:          markupsafe: 3.0.2
2025-05-04 00:42:53,943:INFO:             pickle5: Not installed
2025-05-04 00:42:53,943:INFO:         cloudpickle: 2.2.1
2025-05-04 00:42:53,943:INFO:         deprecation: 2.1.0
2025-05-04 00:42:53,943:INFO:              xxhash: 3.5.0
2025-05-04 00:42:53,943:INFO:           wurlitzer: Not installed
2025-05-04 00:42:53,943:INFO:PyCaret optional dependencies:
2025-05-04 00:42:53,959:INFO:                shap: 0.47.2
2025-05-04 00:42:53,959:INFO:           interpret: Not installed
2025-05-04 00:42:53,959:INFO:                umap: Not installed
2025-05-04 00:42:53,959:INFO:     ydata_profiling: 4.16.1
2025-05-04 00:42:53,959:INFO:  explainerdashboard: Not installed
2025-05-04 00:42:53,959:INFO:             autoviz: Not installed
2025-05-04 00:42:53,959:INFO:           fairlearn: Not installed
2025-05-04 00:42:53,959:INFO:          deepchecks: Not installed
2025-05-04 00:42:53,959:INFO:             xgboost: Not installed
2025-05-04 00:42:53,959:INFO:            catboost: Not installed
2025-05-04 00:42:53,959:INFO:              kmodes: Not installed
2025-05-04 00:42:53,959:INFO:             mlxtend: Not installed
2025-05-04 00:42:53,959:INFO:       statsforecast: Not installed
2025-05-04 00:42:53,959:INFO:        tune_sklearn: Not installed
2025-05-04 00:42:53,959:INFO:                 ray: Not installed
2025-05-04 00:42:53,959:INFO:            hyperopt: Not installed
2025-05-04 00:42:53,959:INFO:              optuna: 4.3.0
2025-05-04 00:42:53,959:INFO:               skopt: Not installed
2025-05-04 00:42:53,959:INFO:              mlflow: 2.22.0
2025-05-04 00:42:53,959:INFO:              gradio: Not installed
2025-05-04 00:42:53,959:INFO:             fastapi: 0.115.12
2025-05-04 00:42:53,959:INFO:             uvicorn: 0.34.2
2025-05-04 00:42:53,959:INFO:              m2cgen: Not installed
2025-05-04 00:42:53,959:INFO:           evidently: 0.7.3
2025-05-04 00:42:53,959:INFO:               fugue: Not installed
2025-05-04 00:42:53,959:INFO:           streamlit: Not installed
2025-05-04 00:42:53,959:INFO:             prophet: Not installed
2025-05-04 00:42:53,959:INFO:None
2025-05-04 00:42:53,959:INFO:Set up data.
2025-05-04 00:42:53,972:INFO:Set up folding strategy.
2025-05-04 00:42:53,972:INFO:Set up train/test split.
2025-05-04 00:42:53,992:INFO:Set up index.
2025-05-04 00:42:53,992:INFO:Assigning column types.
2025-05-04 00:42:53,997:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-04 00:42:54,055:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-04 00:42:54,061:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-04 00:42:54,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:42:54,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:42:54,161:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-04 00:42:54,163:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-04 00:42:54,197:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:42:54,197:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:42:54,197:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-04 00:42:54,239:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-04 00:42:54,277:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:42:54,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:42:54,359:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-04 00:42:54,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:42:54,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:42:54,430:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-04 00:42:54,535:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:42:54,535:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:42:54,613:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:42:54,613:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:42:54,632:INFO:Preparing preprocessing pipeline...
2025-05-04 00:42:54,634:INFO:Set up simple imputation.
2025-05-04 00:42:54,636:INFO:Set up encoding of ordinal features.
2025-05-04 00:42:54,638:INFO:Set up encoding of categorical features.
2025-05-04 00:42:54,640:INFO:Set up column name cleaning.
2025-05-04 00:42:54,711:INFO:Finished creating preprocessing pipeline.
2025-05-04 00:42:54,740:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-05-04 00:42:54,742:INFO:Creating final display dataframe.
2025-05-04 00:42:54,958:INFO:Setup _display_container:                     Description               Value
0                    Session id                   1
1                        Target         Dropped_out
2                   Target type              Binary
3           Original data shape           (249, 17)
4        Transformed data shape            (249, 6)
5   Transformed train set shape            (174, 6)
6    Transformed test set shape             (75, 6)
7               Ignore features                  11
8              Numeric features                   4
9          Categorical features                   1
10     Rows with missing values               38.2%
11                   Preprocess                True
12              Imputation type              simple
13           Numeric imputation                mean
14       Categorical imputation                mode
15     Maximum one-hot encoding                  25
16              Encoding method                None
17               Fold Generator     StratifiedKFold
18                  Fold Number                   5
19                     CPU Jobs                  -1
20                      Use GPU               False
21               Log Experiment        MlflowLogger
22              Experiment Name  automl_bigdata_exp
23                          USI                ca33
2025-05-04 00:42:55,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:42:55,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:42:55,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:42:55,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:42:55,303:INFO:Logging experiment in loggers
2025-05-04 00:42:55,389:INFO:SubProcess save_model() called ==================================
2025-05-04 00:42:55,425:INFO:Initializing save_model()
2025-05-04 00:42:55,425:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\nkluo\AppData\Local\Temp\tmp7icoc7qe\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-04 00:42:55,425:INFO:Adding model into prep_pipe
2025-05-04 00:42:55,425:WARNING:Only Model saved as it was a pipeline.
2025-05-04 00:42:55,437:INFO:C:\Users\nkluo\AppData\Local\Temp\tmp7icoc7qe\Transformation Pipeline.pkl saved in current working directory
2025-05-04 00:42:55,453:INFO:Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-05-04 00:42:55,453:INFO:save_model() successfully completed......................................
2025-05-04 00:42:55,626:INFO:SubProcess save_model() end ==================================
2025-05-04 00:42:55,644:INFO:setup() successfully completed in 1.53s...............
2025-05-04 00:42:55,749:INFO:Initializing compare_models()
2025-05-04 00:42:55,749:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, include=['lr', 'ridge', 'lightgbm', 'rf', 'et'], fold=5, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=False, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, 'include': ['lr', 'ridge', 'lightgbm', 'rf', 'et'], 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': False, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-05-04 00:42:55,749:INFO:Checking exceptions
2025-05-04 00:42:55,758:INFO:Preparing display monitor
2025-05-04 00:42:55,764:INFO:Initializing Logistic Regression
2025-05-04 00:42:55,764:INFO:Total runtime is 0.0 minutes
2025-05-04 00:42:55,764:INFO:SubProcess create_model() called ==================================
2025-05-04 00:42:55,764:INFO:Initializing create_model()
2025-05-04 00:42:55,764:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015F86AE4730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:42:55,764:INFO:Checking exceptions
2025-05-04 00:42:55,764:INFO:Importing libraries
2025-05-04 00:42:55,764:INFO:Copying training dataset
2025-05-04 00:42:55,769:INFO:Defining folds
2025-05-04 00:42:55,769:INFO:Declaring metric variables
2025-05-04 00:42:55,769:INFO:Importing untrained model
2025-05-04 00:42:55,769:INFO:Logistic Regression Imported successfully
2025-05-04 00:42:55,769:INFO:Starting cross validation
2025-05-04 00:42:55,771:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:43:02,937:INFO:Calculating mean and std
2025-05-04 00:43:02,939:INFO:Creating metrics dataframe
2025-05-04 00:43:02,943:INFO:Uploading results into container
2025-05-04 00:43:02,953:INFO:Uploading model into container now
2025-05-04 00:43:02,955:INFO:_master_model_container: 1
2025-05-04 00:43:02,955:INFO:_display_container: 2
2025-05-04 00:43:02,955:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-04 00:43:02,957:INFO:create_model() successfully completed......................................
2025-05-04 00:43:03,190:INFO:SubProcess create_model() end ==================================
2025-05-04 00:43:03,190:INFO:Creating metrics dataframe
2025-05-04 00:43:03,209:INFO:Initializing Ridge Classifier
2025-05-04 00:43:03,211:INFO:Total runtime is 0.12408827543258667 minutes
2025-05-04 00:43:03,211:INFO:SubProcess create_model() called ==================================
2025-05-04 00:43:03,211:INFO:Initializing create_model()
2025-05-04 00:43:03,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015F86AE4730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:43:03,211:INFO:Checking exceptions
2025-05-04 00:43:03,211:INFO:Importing libraries
2025-05-04 00:43:03,211:INFO:Copying training dataset
2025-05-04 00:43:03,215:INFO:Defining folds
2025-05-04 00:43:03,215:INFO:Declaring metric variables
2025-05-04 00:43:03,215:INFO:Importing untrained model
2025-05-04 00:43:03,215:INFO:Ridge Classifier Imported successfully
2025-05-04 00:43:03,217:INFO:Starting cross validation
2025-05-04 00:43:03,217:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:43:08,480:INFO:Calculating mean and std
2025-05-04 00:43:08,480:INFO:Creating metrics dataframe
2025-05-04 00:43:08,496:INFO:Uploading results into container
2025-05-04 00:43:08,498:INFO:Uploading model into container now
2025-05-04 00:43:08,498:INFO:_master_model_container: 2
2025-05-04 00:43:08,498:INFO:_display_container: 2
2025-05-04 00:43:08,498:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1, solver='auto',
                tol=0.0001)
2025-05-04 00:43:08,498:INFO:create_model() successfully completed......................................
2025-05-04 00:43:08,733:INFO:SubProcess create_model() end ==================================
2025-05-04 00:43:08,733:INFO:Creating metrics dataframe
2025-05-04 00:43:08,752:INFO:Initializing Light Gradient Boosting Machine
2025-05-04 00:43:08,752:INFO:Total runtime is 0.2164600173632304 minutes
2025-05-04 00:43:08,752:INFO:SubProcess create_model() called ==================================
2025-05-04 00:43:08,754:INFO:Initializing create_model()
2025-05-04 00:43:08,754:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015F86AE4730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:43:08,754:INFO:Checking exceptions
2025-05-04 00:43:08,754:INFO:Importing libraries
2025-05-04 00:43:08,754:INFO:Copying training dataset
2025-05-04 00:43:08,758:INFO:Defining folds
2025-05-04 00:43:08,758:INFO:Declaring metric variables
2025-05-04 00:43:08,758:INFO:Importing untrained model
2025-05-04 00:43:08,760:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-04 00:43:08,760:INFO:Starting cross validation
2025-05-04 00:43:08,760:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:43:09,284:INFO:Calculating mean and std
2025-05-04 00:43:09,286:INFO:Creating metrics dataframe
2025-05-04 00:43:09,295:INFO:Uploading results into container
2025-05-04 00:43:09,297:INFO:Uploading model into container now
2025-05-04 00:43:09,299:INFO:_master_model_container: 3
2025-05-04 00:43:09,299:INFO:_display_container: 2
2025-05-04 00:43:09,301:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-04 00:43:09,301:INFO:create_model() successfully completed......................................
2025-05-04 00:43:09,492:INFO:SubProcess create_model() end ==================================
2025-05-04 00:43:09,492:INFO:Creating metrics dataframe
2025-05-04 00:43:09,504:INFO:Initializing Random Forest Classifier
2025-05-04 00:43:09,504:INFO:Total runtime is 0.2290066957473755 minutes
2025-05-04 00:43:09,504:INFO:SubProcess create_model() called ==================================
2025-05-04 00:43:09,504:INFO:Initializing create_model()
2025-05-04 00:43:09,504:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015F86AE4730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:43:09,504:INFO:Checking exceptions
2025-05-04 00:43:09,504:INFO:Importing libraries
2025-05-04 00:43:09,504:INFO:Copying training dataset
2025-05-04 00:43:09,504:INFO:Defining folds
2025-05-04 00:43:09,504:INFO:Declaring metric variables
2025-05-04 00:43:09,504:INFO:Importing untrained model
2025-05-04 00:43:09,504:INFO:Random Forest Classifier Imported successfully
2025-05-04 00:43:09,504:INFO:Starting cross validation
2025-05-04 00:43:09,504:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:43:10,204:INFO:Calculating mean and std
2025-05-04 00:43:10,204:INFO:Creating metrics dataframe
2025-05-04 00:43:10,204:INFO:Uploading results into container
2025-05-04 00:43:10,204:INFO:Uploading model into container now
2025-05-04 00:43:10,204:INFO:_master_model_container: 4
2025-05-04 00:43:10,204:INFO:_display_container: 2
2025-05-04 00:43:10,204:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False)
2025-05-04 00:43:10,204:INFO:create_model() successfully completed......................................
2025-05-04 00:43:10,419:INFO:SubProcess create_model() end ==================================
2025-05-04 00:43:10,419:INFO:Creating metrics dataframe
2025-05-04 00:43:10,428:INFO:Initializing Extra Trees Classifier
2025-05-04 00:43:10,428:INFO:Total runtime is 0.2443978230158488 minutes
2025-05-04 00:43:10,428:INFO:SubProcess create_model() called ==================================
2025-05-04 00:43:10,430:INFO:Initializing create_model()
2025-05-04 00:43:10,430:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015F86AE4730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:43:10,430:INFO:Checking exceptions
2025-05-04 00:43:10,430:INFO:Importing libraries
2025-05-04 00:43:10,430:INFO:Copying training dataset
2025-05-04 00:43:10,434:INFO:Defining folds
2025-05-04 00:43:10,434:INFO:Declaring metric variables
2025-05-04 00:43:10,434:INFO:Importing untrained model
2025-05-04 00:43:10,434:INFO:Extra Trees Classifier Imported successfully
2025-05-04 00:43:10,434:INFO:Starting cross validation
2025-05-04 00:43:10,434:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:43:11,128:INFO:Calculating mean and std
2025-05-04 00:43:11,128:INFO:Creating metrics dataframe
2025-05-04 00:43:11,135:INFO:Uploading results into container
2025-05-04 00:43:11,135:INFO:Uploading model into container now
2025-05-04 00:43:11,150:INFO:_master_model_container: 5
2025-05-04 00:43:11,150:INFO:_display_container: 2
2025-05-04 00:43:11,151:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1, verbose=0,
                     warm_start=False)
2025-05-04 00:43:11,151:INFO:create_model() successfully completed......................................
2025-05-04 00:43:11,400:INFO:SubProcess create_model() end ==================================
2025-05-04 00:43:11,400:INFO:Creating metrics dataframe
2025-05-04 00:43:11,412:INFO:Initializing create_model()
2025-05-04 00:43:11,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:43:11,414:INFO:Checking exceptions
2025-05-04 00:43:11,414:INFO:Importing libraries
2025-05-04 00:43:11,414:INFO:Copying training dataset
2025-05-04 00:43:11,421:INFO:Defining folds
2025-05-04 00:43:11,421:INFO:Declaring metric variables
2025-05-04 00:43:11,421:INFO:Importing untrained model
2025-05-04 00:43:11,421:INFO:Declaring custom model
2025-05-04 00:43:11,423:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-04 00:43:11,423:INFO:Cross validation set to False
2025-05-04 00:43:11,423:INFO:Fitting Model
2025-05-04 00:43:11,484:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-05-04 00:43:11,486:INFO:[LightGBM] [Info] Number of positive: 118, number of negative: 56
2025-05-04 00:43:11,486:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.
2025-05-04 00:43:11,486:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-04 00:43:11,486:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-04 00:43:11,486:INFO:[LightGBM] [Info] Total Bins 8
2025-05-04 00:43:11,488:INFO:[LightGBM] [Info] Number of data points in the train set: 174, number of used features: 4
2025-05-04 00:43:11,488:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.678161 -> initscore=0.745333
2025-05-04 00:43:11,488:INFO:[LightGBM] [Info] Start training from score 0.745333
2025-05-04 00:43:11,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:11,552:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-04 00:43:11,552:INFO:create_model() successfully completed......................................
2025-05-04 00:43:11,944:INFO:Creating Dashboard logs
2025-05-04 00:43:11,945:INFO:Model: Light Gradient Boosting Machine
2025-05-04 00:43:11,976:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 1, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-05-04 00:43:12,129:INFO:Initializing predict_model()
2025-05-04 00:43:12,129:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000015F86B7D090>)
2025-05-04 00:43:12,129:INFO:Checking exceptions
2025-05-04 00:43:12,129:INFO:Preloading libraries
2025-05-04 00:43:12,563:WARNING:c:\LKN\venv\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2025-05-04 00:43:13,017:INFO:Creating Dashboard logs
2025-05-04 00:43:13,019:INFO:Model: Extra Trees Classifier
2025-05-04 00:43:13,033:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}
2025-05-04 00:43:13,476:INFO:Creating Dashboard logs
2025-05-04 00:43:13,482:INFO:Model: Random Forest Classifier
2025-05-04 00:43:13,517:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}
2025-05-04 00:43:13,865:INFO:Creating Dashboard logs
2025-05-04 00:43:13,872:INFO:Model: Ridge Classifier
2025-05-04 00:43:13,891:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 1, 'solver': 'auto', 'tol': 0.0001}
2025-05-04 00:43:14,237:INFO:Creating Dashboard logs
2025-05-04 00:43:14,237:INFO:Model: Logistic Regression
2025-05-04 00:43:14,268:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 1, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-05-04 00:43:14,635:INFO:_master_model_container: 5
2025-05-04 00:43:14,635:INFO:_display_container: 2
2025-05-04 00:43:14,649:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-04 00:43:14,649:INFO:compare_models() successfully completed......................................
2025-05-04 00:43:14,760:INFO:Initializing create_model()
2025-05-04 00:43:14,760:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, estimator=lr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:43:14,760:INFO:Checking exceptions
2025-05-04 00:43:14,760:INFO:Importing libraries
2025-05-04 00:43:14,760:INFO:Copying training dataset
2025-05-04 00:43:14,776:INFO:Defining folds
2025-05-04 00:43:14,776:INFO:Declaring metric variables
2025-05-04 00:43:14,776:INFO:Importing untrained model
2025-05-04 00:43:14,776:INFO:Logistic Regression Imported successfully
2025-05-04 00:43:14,776:INFO:Starting cross validation
2025-05-04 00:43:14,776:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:43:15,014:INFO:Calculating mean and std
2025-05-04 00:43:15,015:INFO:Creating metrics dataframe
2025-05-04 00:43:15,015:INFO:Finalizing model
2025-05-04 00:43:15,058:INFO:Creating Dashboard logs
2025-05-04 00:43:15,058:INFO:Model: Logistic Regression
2025-05-04 00:43:15,094:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 1, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-05-04 00:43:15,220:INFO:Initializing predict_model()
2025-05-04 00:43:15,220:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000015F86AC2170>)
2025-05-04 00:43:15,220:INFO:Checking exceptions
2025-05-04 00:43:15,220:INFO:Preloading libraries
2025-05-04 00:43:15,759:INFO:Uploading results into container
2025-05-04 00:43:15,759:INFO:Uploading model into container now
2025-05-04 00:43:15,759:INFO:_master_model_container: 6
2025-05-04 00:43:15,775:INFO:_display_container: 3
2025-05-04 00:43:15,775:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-04 00:43:15,775:INFO:create_model() successfully completed......................................
2025-05-04 00:43:15,982:INFO:Initializing plot_model()
2025-05-04 00:43:15,982:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, system=True)
2025-05-04 00:43:15,984:INFO:Checking exceptions
2025-05-04 00:43:15,985:INFO:Preloading libraries
2025-05-04 00:43:15,987:INFO:Copying training dataset
2025-05-04 00:43:15,987:INFO:Plot type: feature
2025-05-04 00:43:16,094:WARNING:c:\LKN\venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1845: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  plt.figure(figsize=(8, 5 * (n // 10)), dpi=_base_dpi * scale)

2025-05-04 00:43:16,339:INFO:Saving 'Feature Importance.png'
2025-05-04 00:43:16,507:INFO:Visual Rendered Successfully
2025-05-04 00:43:16,680:INFO:plot_model() successfully completed......................................
2025-05-04 00:43:16,791:INFO:Initializing create_model()
2025-05-04 00:43:16,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, estimator=ridge, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:43:16,791:INFO:Checking exceptions
2025-05-04 00:43:16,791:INFO:Importing libraries
2025-05-04 00:43:16,791:INFO:Copying training dataset
2025-05-04 00:43:16,797:INFO:Defining folds
2025-05-04 00:43:16,797:INFO:Declaring metric variables
2025-05-04 00:43:16,797:INFO:Importing untrained model
2025-05-04 00:43:16,797:INFO:Ridge Classifier Imported successfully
2025-05-04 00:43:16,797:INFO:Starting cross validation
2025-05-04 00:43:16,797:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:43:16,950:INFO:Calculating mean and std
2025-05-04 00:43:16,950:INFO:Creating metrics dataframe
2025-05-04 00:43:16,950:INFO:Finalizing model
2025-05-04 00:43:16,997:INFO:Creating Dashboard logs
2025-05-04 00:43:16,997:INFO:Model: Ridge Classifier
2025-05-04 00:43:17,029:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 1, 'solver': 'auto', 'tol': 0.0001}
2025-05-04 00:43:17,173:INFO:Initializing predict_model()
2025-05-04 00:43:17,173:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1, solver='auto',
                tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000015F86AC2170>)
2025-05-04 00:43:17,173:INFO:Checking exceptions
2025-05-04 00:43:17,173:INFO:Preloading libraries
2025-05-04 00:43:17,765:INFO:Uploading results into container
2025-05-04 00:43:17,765:INFO:Uploading model into container now
2025-05-04 00:43:17,765:INFO:_master_model_container: 7
2025-05-04 00:43:17,765:INFO:_display_container: 4
2025-05-04 00:43:17,765:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1, solver='auto',
                tol=0.0001)
2025-05-04 00:43:17,765:INFO:create_model() successfully completed......................................
2025-05-04 00:43:18,301:INFO:Initializing plot_model()
2025-05-04 00:43:18,301:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, system=True)
2025-05-04 00:43:18,301:INFO:Checking exceptions
2025-05-04 00:43:18,301:INFO:Preloading libraries
2025-05-04 00:43:18,301:INFO:Copying training dataset
2025-05-04 00:43:18,301:INFO:Plot type: feature
2025-05-04 00:43:18,426:WARNING:c:\LKN\venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1845: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  plt.figure(figsize=(8, 5 * (n // 10)), dpi=_base_dpi * scale)

2025-05-04 00:43:18,630:INFO:Saving 'Feature Importance.png'
2025-05-04 00:43:18,811:INFO:Visual Rendered Successfully
2025-05-04 00:43:19,002:INFO:plot_model() successfully completed......................................
2025-05-04 00:43:19,131:INFO:Initializing create_model()
2025-05-04 00:43:19,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:43:19,131:INFO:Checking exceptions
2025-05-04 00:43:19,131:INFO:Importing libraries
2025-05-04 00:43:19,131:INFO:Copying training dataset
2025-05-04 00:43:19,131:INFO:Defining folds
2025-05-04 00:43:19,131:INFO:Declaring metric variables
2025-05-04 00:43:19,131:INFO:Importing untrained model
2025-05-04 00:43:19,131:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-04 00:43:19,131:INFO:Starting cross validation
2025-05-04 00:43:19,131:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:43:19,764:INFO:Calculating mean and std
2025-05-04 00:43:19,765:INFO:Creating metrics dataframe
2025-05-04 00:43:19,770:INFO:Finalizing model
2025-05-04 00:43:19,843:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-05-04 00:43:19,844:INFO:[LightGBM] [Info] Number of positive: 118, number of negative: 56
2025-05-04 00:43:19,845:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.
2025-05-04 00:43:19,845:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-04 00:43:19,845:INFO:[LightGBM] [Info] Total Bins 8
2025-05-04 00:43:19,846:INFO:[LightGBM] [Info] Number of data points in the train set: 174, number of used features: 4
2025-05-04 00:43:19,846:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.678161 -> initscore=0.745333
2025-05-04 00:43:19,846:INFO:[LightGBM] [Info] Start training from score 0.745333
2025-05-04 00:43:19,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-04 00:43:19,909:INFO:Creating Dashboard logs
2025-05-04 00:43:19,911:INFO:Model: Light Gradient Boosting Machine
2025-05-04 00:43:19,969:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 1, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-05-04 00:43:20,130:INFO:Initializing predict_model()
2025-05-04 00:43:20,130:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000015F86AC2170>)
2025-05-04 00:43:20,130:INFO:Checking exceptions
2025-05-04 00:43:20,130:INFO:Preloading libraries
2025-05-04 00:43:20,825:INFO:Uploading results into container
2025-05-04 00:43:20,830:INFO:Uploading model into container now
2025-05-04 00:43:20,830:INFO:_master_model_container: 8
2025-05-04 00:43:20,830:INFO:_display_container: 5
2025-05-04 00:43:20,832:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-04 00:43:20,832:INFO:create_model() successfully completed......................................
2025-05-04 00:43:21,031:INFO:Initializing plot_model()
2025-05-04 00:43:21,031:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, system=True)
2025-05-04 00:43:21,042:INFO:Checking exceptions
2025-05-04 00:43:21,044:INFO:Preloading libraries
2025-05-04 00:43:21,048:INFO:Copying training dataset
2025-05-04 00:43:21,048:INFO:Plot type: feature
2025-05-04 00:43:21,050:WARNING:No coef_ found. Trying feature_importances_
2025-05-04 00:43:21,136:WARNING:c:\LKN\venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1845: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  plt.figure(figsize=(8, 5 * (n // 10)), dpi=_base_dpi * scale)

2025-05-04 00:43:21,280:INFO:Saving 'Feature Importance.png'
2025-05-04 00:43:21,410:INFO:Visual Rendered Successfully
2025-05-04 00:43:21,594:INFO:plot_model() successfully completed......................................
2025-05-04 00:43:21,759:INFO:Initializing create_model()
2025-05-04 00:43:21,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:43:21,759:INFO:Checking exceptions
2025-05-04 00:43:21,762:INFO:Importing libraries
2025-05-04 00:43:21,762:INFO:Copying training dataset
2025-05-04 00:43:21,768:INFO:Defining folds
2025-05-04 00:43:21,768:INFO:Declaring metric variables
2025-05-04 00:43:21,770:INFO:Importing untrained model
2025-05-04 00:43:21,770:INFO:Random Forest Classifier Imported successfully
2025-05-04 00:43:21,770:INFO:Starting cross validation
2025-05-04 00:43:21,775:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:43:22,412:INFO:Calculating mean and std
2025-05-04 00:43:22,412:INFO:Creating metrics dataframe
2025-05-04 00:43:22,412:INFO:Finalizing model
2025-05-04 00:43:22,665:INFO:Creating Dashboard logs
2025-05-04 00:43:22,665:INFO:Model: Random Forest Classifier
2025-05-04 00:43:22,678:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}
2025-05-04 00:43:22,816:INFO:Initializing predict_model()
2025-05-04 00:43:22,817:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000015F86CEE4D0>)
2025-05-04 00:43:22,817:INFO:Checking exceptions
2025-05-04 00:43:22,817:INFO:Preloading libraries
2025-05-04 00:43:23,483:INFO:Uploading results into container
2025-05-04 00:43:23,495:INFO:Uploading model into container now
2025-05-04 00:43:23,496:INFO:_master_model_container: 9
2025-05-04 00:43:23,496:INFO:_display_container: 6
2025-05-04 00:43:23,496:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False)
2025-05-04 00:43:23,496:INFO:create_model() successfully completed......................................
2025-05-04 00:43:23,740:INFO:Initializing plot_model()
2025-05-04 00:43:23,740:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, system=True)
2025-05-04 00:43:23,741:INFO:Checking exceptions
2025-05-04 00:43:23,771:INFO:Preloading libraries
2025-05-04 00:43:23,779:INFO:Copying training dataset
2025-05-04 00:43:23,779:INFO:Plot type: feature
2025-05-04 00:43:23,779:WARNING:No coef_ found. Trying feature_importances_
2025-05-04 00:43:23,856:WARNING:c:\LKN\venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1845: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  plt.figure(figsize=(8, 5 * (n // 10)), dpi=_base_dpi * scale)

2025-05-04 00:43:23,979:INFO:Saving 'Feature Importance.png'
2025-05-04 00:43:24,112:INFO:Visual Rendered Successfully
2025-05-04 00:43:24,278:INFO:plot_model() successfully completed......................................
2025-05-04 00:43:24,396:INFO:Initializing create_model()
2025-05-04 00:43:24,396:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, estimator=et, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:43:24,396:INFO:Checking exceptions
2025-05-04 00:43:24,400:INFO:Importing libraries
2025-05-04 00:43:24,400:INFO:Copying training dataset
2025-05-04 00:43:24,404:INFO:Defining folds
2025-05-04 00:43:24,404:INFO:Declaring metric variables
2025-05-04 00:43:24,404:INFO:Importing untrained model
2025-05-04 00:43:24,404:INFO:Extra Trees Classifier Imported successfully
2025-05-04 00:43:24,404:INFO:Starting cross validation
2025-05-04 00:43:24,406:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:43:24,898:INFO:Calculating mean and std
2025-05-04 00:43:24,898:INFO:Creating metrics dataframe
2025-05-04 00:43:24,898:INFO:Finalizing model
2025-05-04 00:43:25,091:INFO:Creating Dashboard logs
2025-05-04 00:43:25,091:INFO:Model: Extra Trees Classifier
2025-05-04 00:43:25,138:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}
2025-05-04 00:43:25,276:INFO:Initializing predict_model()
2025-05-04 00:43:25,276:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1, verbose=0,
                     warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000015F86B7D870>)
2025-05-04 00:43:25,277:INFO:Checking exceptions
2025-05-04 00:43:25,277:INFO:Preloading libraries
2025-05-04 00:43:25,927:INFO:Uploading results into container
2025-05-04 00:43:25,928:INFO:Uploading model into container now
2025-05-04 00:43:25,928:INFO:_master_model_container: 10
2025-05-04 00:43:25,928:INFO:_display_container: 7
2025-05-04 00:43:25,929:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1, verbose=0,
                     warm_start=False)
2025-05-04 00:43:25,929:INFO:create_model() successfully completed......................................
2025-05-04 00:43:26,167:INFO:Initializing plot_model()
2025-05-04 00:43:26,167:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1, verbose=0,
                     warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F866FC8B0>, system=True)
2025-05-04 00:43:26,167:INFO:Checking exceptions
2025-05-04 00:43:26,198:INFO:Preloading libraries
2025-05-04 00:43:26,198:INFO:Copying training dataset
2025-05-04 00:43:26,198:INFO:Plot type: feature
2025-05-04 00:43:26,198:WARNING:No coef_ found. Trying feature_importances_
2025-05-04 00:43:26,261:WARNING:c:\LKN\venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1845: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  plt.figure(figsize=(8, 5 * (n // 10)), dpi=_base_dpi * scale)

2025-05-04 00:43:26,397:INFO:Saving 'Feature Importance.png'
2025-05-04 00:43:26,521:INFO:Visual Rendered Successfully
2025-05-04 00:43:26,696:INFO:plot_model() successfully completed......................................
2025-05-04 00:47:45,093:INFO:PyCaret ClassificationExperiment
2025-05-04 00:47:45,093:INFO:Logging name: automl_bigdata_exp
2025-05-04 00:47:45,093:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-04 00:47:45,093:INFO:version 3.3.2
2025-05-04 00:47:45,093:INFO:Initializing setup()
2025-05-04 00:47:45,093:INFO:self.USI: bd30
2025-05-04 00:47:45,093:INFO:self._variable_keys: {'y', 'fix_imbalance', 'exp_name_log', 'is_multiclass', 'fold_shuffle_param', 'X_train', 'fold_generator', 'USI', 'X', '_available_plots', 'memory', 'idx', 'logging_param', 'y_train', '_ml_usecase', 'n_jobs_param', 'seed', 'gpu_param', 'X_test', 'target_param', 'exp_id', 'data', 'log_plots_param', 'y_test', 'fold_groups_param', 'pipeline', 'html_param', 'gpu_n_jobs_param'}
2025-05-04 00:47:45,093:INFO:Checking environment
2025-05-04 00:47:45,093:INFO:python_version: 3.10.11
2025-05-04 00:47:45,093:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2025-05-04 00:47:45,094:INFO:machine: AMD64
2025-05-04 00:47:45,094:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-04 00:47:45,096:INFO:Memory: svmem(total=8425017344, available=1163825152, percent=86.2, used=7261192192, free=1163825152)
2025-05-04 00:47:45,096:INFO:Physical Core: 4
2025-05-04 00:47:45,096:INFO:Logical Core: 8
2025-05-04 00:47:45,096:INFO:Checking libraries
2025-05-04 00:47:45,096:INFO:System:
2025-05-04 00:47:45,096:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2025-05-04 00:47:45,096:INFO:executable: c:\LKN\venv\Scripts\python.exe
2025-05-04 00:47:45,096:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-04 00:47:45,096:INFO:PyCaret required dependencies:
2025-05-04 00:47:45,096:INFO:                 pip: 23.0.1
2025-05-04 00:47:45,096:INFO:          setuptools: 65.5.0
2025-05-04 00:47:45,096:INFO:             pycaret: 3.3.2
2025-05-04 00:47:45,096:INFO:             IPython: 8.36.0
2025-05-04 00:47:45,096:INFO:          ipywidgets: 8.1.6
2025-05-04 00:47:45,096:INFO:                tqdm: 4.67.1
2025-05-04 00:47:45,096:INFO:               numpy: 1.26.4
2025-05-04 00:47:45,096:INFO:              pandas: 1.5.3
2025-05-04 00:47:45,096:INFO:              jinja2: 3.1.6
2025-05-04 00:47:45,096:INFO:               scipy: 1.11.4
2025-05-04 00:47:45,096:INFO:              joblib: 1.3.2
2025-05-04 00:47:45,096:INFO:             sklearn: 1.4.2
2025-05-04 00:47:45,096:INFO:                pyod: 2.0.4
2025-05-04 00:47:45,096:INFO:            imblearn: 0.13.0
2025-05-04 00:47:45,096:INFO:   category_encoders: 2.7.0
2025-05-04 00:47:45,096:INFO:            lightgbm: 4.6.0
2025-05-04 00:47:45,096:INFO:               numba: 0.61.0
2025-05-04 00:47:45,096:INFO:            requests: 2.32.3
2025-05-04 00:47:45,096:INFO:          matplotlib: 3.7.5
2025-05-04 00:47:45,096:INFO:          scikitplot: 0.3.7
2025-05-04 00:47:45,096:INFO:         yellowbrick: 1.5
2025-05-04 00:47:45,096:INFO:              plotly: 5.24.1
2025-05-04 00:47:45,096:INFO:    plotly-resampler: Not installed
2025-05-04 00:47:45,096:INFO:             kaleido: 0.2.1
2025-05-04 00:47:45,096:INFO:           schemdraw: 0.15
2025-05-04 00:47:45,096:INFO:         statsmodels: 0.14.4
2025-05-04 00:47:45,096:INFO:              sktime: 0.26.0
2025-05-04 00:47:45,096:INFO:               tbats: 1.1.3
2025-05-04 00:47:45,096:INFO:            pmdarima: 2.0.4
2025-05-04 00:47:45,096:INFO:              psutil: 7.0.0
2025-05-04 00:47:45,096:INFO:          markupsafe: 3.0.2
2025-05-04 00:47:45,096:INFO:             pickle5: Not installed
2025-05-04 00:47:45,096:INFO:         cloudpickle: 2.2.1
2025-05-04 00:47:45,096:INFO:         deprecation: 2.1.0
2025-05-04 00:47:45,096:INFO:              xxhash: 3.5.0
2025-05-04 00:47:45,096:INFO:           wurlitzer: Not installed
2025-05-04 00:47:45,096:INFO:PyCaret optional dependencies:
2025-05-04 00:47:45,096:INFO:                shap: 0.47.2
2025-05-04 00:47:45,096:INFO:           interpret: Not installed
2025-05-04 00:47:45,096:INFO:                umap: Not installed
2025-05-04 00:47:45,096:INFO:     ydata_profiling: 4.16.1
2025-05-04 00:47:45,096:INFO:  explainerdashboard: Not installed
2025-05-04 00:47:45,096:INFO:             autoviz: Not installed
2025-05-04 00:47:45,096:INFO:           fairlearn: Not installed
2025-05-04 00:47:45,096:INFO:          deepchecks: Not installed
2025-05-04 00:47:45,102:INFO:             xgboost: Not installed
2025-05-04 00:47:45,102:INFO:            catboost: Not installed
2025-05-04 00:47:45,102:INFO:              kmodes: Not installed
2025-05-04 00:47:45,102:INFO:             mlxtend: Not installed
2025-05-04 00:47:45,102:INFO:       statsforecast: Not installed
2025-05-04 00:47:45,102:INFO:        tune_sklearn: Not installed
2025-05-04 00:47:45,102:INFO:                 ray: Not installed
2025-05-04 00:47:45,102:INFO:            hyperopt: Not installed
2025-05-04 00:47:45,102:INFO:              optuna: 4.3.0
2025-05-04 00:47:45,102:INFO:               skopt: Not installed
2025-05-04 00:47:45,102:INFO:              mlflow: 2.22.0
2025-05-04 00:47:45,102:INFO:              gradio: Not installed
2025-05-04 00:47:45,102:INFO:             fastapi: 0.115.12
2025-05-04 00:47:45,102:INFO:             uvicorn: 0.34.2
2025-05-04 00:47:45,102:INFO:              m2cgen: Not installed
2025-05-04 00:47:45,102:INFO:           evidently: 0.7.3
2025-05-04 00:47:45,102:INFO:               fugue: Not installed
2025-05-04 00:47:45,102:INFO:           streamlit: Not installed
2025-05-04 00:47:45,102:INFO:             prophet: Not installed
2025-05-04 00:47:45,102:INFO:None
2025-05-04 00:47:45,102:INFO:Set up data.
2025-05-04 00:47:45,109:INFO:Set up folding strategy.
2025-05-04 00:47:45,109:INFO:Set up train/test split.
2025-05-04 00:47:45,109:INFO:Set up index.
2025-05-04 00:47:45,109:INFO:Assigning column types.
2025-05-04 00:47:45,109:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-04 00:47:45,191:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:47:45,206:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:47:45,295:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:47:45,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:47:45,296:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-04 00:47:45,378:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:47:45,379:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:47:45,465:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:47:45,465:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:47:45,465:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-04 00:47:45,547:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:47:45,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:47:45,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:47:45,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:47:45,630:INFO:Preparing preprocessing pipeline...
2025-05-04 00:47:45,630:INFO:Set up simple imputation.
2025-05-04 00:47:45,630:INFO:Set up encoding of ordinal features.
2025-05-04 00:47:45,630:INFO:Set up encoding of categorical features.
2025-05-04 00:47:45,630:INFO:Set up column name cleaning.
2025-05-04 00:47:45,697:INFO:Finished creating preprocessing pipeline.
2025-05-04 00:47:45,730:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-05-04 00:47:45,731:INFO:Creating final display dataframe.
2025-05-04 00:47:45,903:INFO:Setup _display_container:                     Description               Value
0                    Session id                   1
1                        Target         Dropped_out
2                   Target type              Binary
3           Original data shape           (249, 17)
4        Transformed data shape            (249, 6)
5   Transformed train set shape            (174, 6)
6    Transformed test set shape             (75, 6)
7               Ignore features                  11
8              Numeric features                   4
9          Categorical features                   1
10     Rows with missing values               38.2%
11                   Preprocess                True
12              Imputation type              simple
13           Numeric imputation                mean
14       Categorical imputation                mode
15     Maximum one-hot encoding                  25
16              Encoding method                None
17               Fold Generator     StratifiedKFold
18                  Fold Number                   5
19                     CPU Jobs                  -1
20                      Use GPU               False
21               Log Experiment        MlflowLogger
22              Experiment Name  automl_bigdata_exp
23                          USI                bd30
2025-05-04 00:47:45,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:47:45,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:47:46,059:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:47:46,059:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:47:46,059:INFO:Logging experiment in loggers
2025-05-04 00:47:46,163:INFO:SubProcess save_model() called ==================================
2025-05-04 00:47:46,211:INFO:Initializing save_model()
2025-05-04 00:47:46,211:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\nkluo\AppData\Local\Temp\tmpud7a8f6k\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-04 00:47:46,211:INFO:Adding model into prep_pipe
2025-05-04 00:47:46,211:WARNING:Only Model saved as it was a pipeline.
2025-05-04 00:47:46,225:INFO:C:\Users\nkluo\AppData\Local\Temp\tmpud7a8f6k\Transformation Pipeline.pkl saved in current working directory
2025-05-04 00:47:46,241:INFO:Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-05-04 00:47:46,241:INFO:save_model() successfully completed......................................
2025-05-04 00:47:46,507:INFO:SubProcess save_model() end ==================================
2025-05-04 00:47:46,557:INFO:setup() successfully completed in 1.0s...............
2025-05-04 00:47:46,640:INFO:Initializing create_model()
2025-05-04 00:47:46,640:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F86C2E950>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:47:46,640:INFO:Checking exceptions
2025-05-04 00:47:46,640:INFO:Importing libraries
2025-05-04 00:47:46,652:INFO:Copying training dataset
2025-05-04 00:47:46,657:INFO:Defining folds
2025-05-04 00:47:46,657:INFO:Declaring metric variables
2025-05-04 00:47:46,661:INFO:Importing untrained model
2025-05-04 00:47:46,661:INFO:Random Forest Classifier Imported successfully
2025-05-04 00:47:46,661:INFO:Starting cross validation
2025-05-04 00:47:46,661:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:47:47,239:INFO:Calculating mean and std
2025-05-04 00:47:47,242:INFO:Creating metrics dataframe
2025-05-04 00:47:47,242:INFO:Finalizing model
2025-05-04 00:47:47,541:INFO:Creating Dashboard logs
2025-05-04 00:47:47,541:INFO:Model: Random Forest Classifier
2025-05-04 00:47:47,557:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}
2025-05-04 00:47:47,723:INFO:Initializing predict_model()
2025-05-04 00:47:47,723:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F86C2E950>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000015F87076E60>)
2025-05-04 00:47:47,723:INFO:Checking exceptions
2025-05-04 00:47:47,723:INFO:Preloading libraries
2025-05-04 00:47:48,389:INFO:Uploading results into container
2025-05-04 00:47:48,390:INFO:Uploading model into container now
2025-05-04 00:47:48,390:INFO:_master_model_container: 11
2025-05-04 00:47:48,390:INFO:_display_container: 8
2025-05-04 00:47:48,390:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False)
2025-05-04 00:47:48,390:INFO:create_model() successfully completed......................................
2025-05-04 00:47:48,595:INFO:Initializing tune_model()
2025-05-04 00:47:48,595:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), fold=5, round=4, n_iter=25, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F86C2E950>)
2025-05-04 00:47:48,595:INFO:Checking exceptions
2025-05-04 00:47:48,607:INFO:Copying training dataset
2025-05-04 00:47:48,607:INFO:Checking base model
2025-05-04 00:47:48,607:INFO:Base model : Random Forest Classifier
2025-05-04 00:47:48,607:INFO:Declaring metric variables
2025-05-04 00:47:48,607:INFO:Defining Hyperparameters
2025-05-04 00:47:48,823:INFO:Tuning with n_jobs=-1
2025-05-04 00:47:48,823:INFO:Initializing RandomizedSearchCV
2025-05-04 00:48:02,985:INFO:best_params: {'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': False}
2025-05-04 00:48:02,985:INFO:Hyperparameter search completed
2025-05-04 00:48:02,985:INFO:SubProcess create_model() called ==================================
2025-05-04 00:48:02,987:INFO:Initializing create_model()
2025-05-04 00:48:02,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F86C2E950>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015F8639A0E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 140, 'min_samples_split': 7, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.001, 'max_features': 1.0, 'max_depth': 10, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': False})
2025-05-04 00:48:02,989:INFO:Checking exceptions
2025-05-04 00:48:02,989:INFO:Importing libraries
2025-05-04 00:48:02,989:INFO:Copying training dataset
2025-05-04 00:48:03,001:INFO:Defining folds
2025-05-04 00:48:03,004:INFO:Declaring metric variables
2025-05-04 00:48:03,004:INFO:Importing untrained model
2025-05-04 00:48:03,004:INFO:Declaring custom model
2025-05-04 00:48:03,008:INFO:Random Forest Classifier Imported successfully
2025-05-04 00:48:03,008:INFO:Starting cross validation
2025-05-04 00:48:03,010:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:48:03,635:INFO:Calculating mean and std
2025-05-04 00:48:03,635:INFO:Creating metrics dataframe
2025-05-04 00:48:03,638:INFO:Finalizing model
2025-05-04 00:48:03,905:INFO:Uploading results into container
2025-05-04 00:48:03,905:INFO:Uploading model into container now
2025-05-04 00:48:03,905:INFO:_master_model_container: 12
2025-05-04 00:48:03,905:INFO:_display_container: 9
2025-05-04 00:48:03,905:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False)
2025-05-04 00:48:03,905:INFO:create_model() successfully completed......................................
2025-05-04 00:48:04,092:INFO:SubProcess create_model() end ==================================
2025-05-04 00:48:04,092:INFO:choose_better activated
2025-05-04 00:48:04,092:INFO:SubProcess create_model() called ==================================
2025-05-04 00:48:04,092:INFO:Initializing create_model()
2025-05-04 00:48:04,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F86C2E950>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 00:48:04,092:INFO:Checking exceptions
2025-05-04 00:48:04,094:INFO:Importing libraries
2025-05-04 00:48:04,094:INFO:Copying training dataset
2025-05-04 00:48:04,100:INFO:Defining folds
2025-05-04 00:48:04,100:INFO:Declaring metric variables
2025-05-04 00:48:04,100:INFO:Importing untrained model
2025-05-04 00:48:04,100:INFO:Declaring custom model
2025-05-04 00:48:04,100:INFO:Random Forest Classifier Imported successfully
2025-05-04 00:48:04,100:INFO:Starting cross validation
2025-05-04 00:48:04,102:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 00:48:04,631:INFO:Calculating mean and std
2025-05-04 00:48:04,632:INFO:Creating metrics dataframe
2025-05-04 00:48:04,632:INFO:Finalizing model
2025-05-04 00:48:04,824:INFO:Uploading results into container
2025-05-04 00:48:04,824:INFO:Uploading model into container now
2025-05-04 00:48:04,824:INFO:_master_model_container: 13
2025-05-04 00:48:04,824:INFO:_display_container: 10
2025-05-04 00:48:04,824:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False)
2025-05-04 00:48:04,824:INFO:create_model() successfully completed......................................
2025-05-04 00:48:05,000:INFO:SubProcess create_model() end ==================================
2025-05-04 00:48:05,000:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False) result for AUC is 0.6439
2025-05-04 00:48:05,000:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False) result for AUC is 0.6472
2025-05-04 00:48:05,000:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False) is best model
2025-05-04 00:48:05,000:INFO:choose_better completed
2025-05-04 00:48:05,000:INFO:Creating Dashboard logs
2025-05-04 00:48:05,000:INFO:Model: Random Forest Classifier
2025-05-04 00:48:05,028:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': {}, 'criterion': 'entropy', 'max_depth': 10, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.001, 'min_samples_leaf': 2, 'min_samples_split': 7, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 140, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}
2025-05-04 00:48:05,169:INFO:Initializing predict_model()
2025-05-04 00:48:05,169:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F86C2E950>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000015F86AC03A0>)
2025-05-04 00:48:05,169:INFO:Checking exceptions
2025-05-04 00:48:05,169:INFO:Preloading libraries
2025-05-04 00:48:05,757:INFO:_master_model_container: 13
2025-05-04 00:48:05,757:INFO:_display_container: 9
2025-05-04 00:48:05,757:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False)
2025-05-04 00:48:05,757:INFO:tune_model() successfully completed......................................
2025-05-04 00:48:06,004:INFO:gpu_param set to False
2025-05-04 00:48:06,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:48:06,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:48:06,167:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:48:06,167:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 00:48:06,169:INFO:Initializing predict_model()
2025-05-04 00:48:06,169:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F86C2E950>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000015F83DDF7F0>)
2025-05-04 00:48:06,169:INFO:Checking exceptions
2025-05-04 00:48:06,169:INFO:Preloading libraries
2025-05-04 00:48:06,561:INFO:Initializing plot_model()
2025-05-04 00:48:06,561:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F86C2E950>, system=True)
2025-05-04 00:48:06,561:INFO:Checking exceptions
2025-05-04 00:48:06,596:INFO:Preloading libraries
2025-05-04 00:48:06,605:INFO:Copying training dataset
2025-05-04 00:48:06,607:INFO:Plot type: feature
2025-05-04 00:48:06,607:WARNING:No coef_ found. Trying feature_importances_
2025-05-04 00:48:06,661:WARNING:c:\LKN\venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1845: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  plt.figure(figsize=(8, 5 * (n // 10)), dpi=_base_dpi * scale)

2025-05-04 00:48:06,817:INFO:Saving 'Feature Importance.png'
2025-05-04 00:48:06,939:INFO:Visual Rendered Successfully
2025-05-04 00:48:07,118:INFO:plot_model() successfully completed......................................
2025-05-04 00:48:07,132:INFO:Initializing plot_model()
2025-05-04 00:48:07,132:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F86C2E950>, system=True)
2025-05-04 00:48:07,132:INFO:Checking exceptions
2025-05-04 00:48:07,177:INFO:Preloading libraries
2025-05-04 00:48:07,183:INFO:Copying training dataset
2025-05-04 00:48:07,183:INFO:Plot type: auc
2025-05-04 00:48:07,369:WARNING:c:\LKN\venv\lib\site-packages\yellowbrick\base.py:111: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  self._fig = plt.gcf()

2025-05-04 00:48:07,491:INFO:Fitting Model
2025-05-04 00:48:07,527:WARNING:c:\LKN\venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-05-04 00:48:07,527:INFO:Scoring test/hold-out set
2025-05-04 00:48:07,626:INFO:Saving 'AUC.png'
2025-05-04 00:48:07,817:INFO:Visual Rendered Successfully
2025-05-04 00:48:08,005:INFO:plot_model() successfully completed......................................
2025-05-04 00:48:08,017:INFO:Initializing plot_model()
2025-05-04 00:48:08,017:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F86C2E950>, system=True)
2025-05-04 00:48:08,017:INFO:Checking exceptions
2025-05-04 00:48:08,065:INFO:Preloading libraries
2025-05-04 00:48:08,080:INFO:Copying training dataset
2025-05-04 00:48:08,080:INFO:Plot type: confusion_matrix
2025-05-04 00:48:08,161:WARNING:c:\LKN\venv\lib\site-packages\yellowbrick\base.py:111: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  self._fig = plt.gcf()

2025-05-04 00:48:08,270:INFO:Fitting Model
2025-05-04 00:48:08,270:WARNING:c:\LKN\venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-05-04 00:48:08,270:INFO:Scoring test/hold-out set
2025-05-04 00:48:08,366:INFO:Saving 'Confusion Matrix.png'
2025-05-04 00:48:08,469:INFO:Visual Rendered Successfully
2025-05-04 00:48:08,651:INFO:plot_model() successfully completed......................................
2025-05-04 00:48:08,666:INFO:Initializing plot_model()
2025-05-04 00:48:08,666:INFO:plot_model(plot=pr, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F86C2E950>, system=True)
2025-05-04 00:48:08,666:INFO:Checking exceptions
2025-05-04 00:48:08,715:INFO:Preloading libraries
2025-05-04 00:48:08,715:INFO:Copying training dataset
2025-05-04 00:48:08,715:INFO:Plot type: pr
2025-05-04 00:48:08,801:WARNING:c:\LKN\venv\lib\site-packages\yellowbrick\base.py:111: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  self._fig = plt.gcf()

2025-05-04 00:48:08,904:INFO:Fitting Model
2025-05-04 00:48:08,904:WARNING:c:\LKN\venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-05-04 00:48:08,906:INFO:Scoring test/hold-out set
2025-05-04 00:48:08,987:INFO:Saving 'Precision Recall.png'
2025-05-04 00:48:09,154:INFO:Visual Rendered Successfully
2025-05-04 00:48:09,336:INFO:plot_model() successfully completed......................................
2025-05-04 00:48:09,348:INFO:Initializing plot_model()
2025-05-04 00:48:09,348:INFO:plot_model(plot=class_report, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015F86C2E950>, system=True)
2025-05-04 00:48:09,356:INFO:Checking exceptions
2025-05-04 00:48:09,399:INFO:Preloading libraries
2025-05-04 00:48:09,409:INFO:Copying training dataset
2025-05-04 00:48:09,409:INFO:Plot type: class_report
2025-05-04 00:48:09,474:WARNING:c:\LKN\venv\lib\site-packages\yellowbrick\base.py:111: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  self._fig = plt.gcf()

2025-05-04 00:48:09,591:INFO:Fitting Model
2025-05-04 00:48:09,591:WARNING:c:\LKN\venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-05-04 00:48:09,591:INFO:Scoring test/hold-out set
2025-05-04 00:48:09,743:INFO:Saving 'Class Report.png'
2025-05-04 00:48:09,934:INFO:Visual Rendered Successfully
2025-05-04 00:48:10,119:INFO:plot_model() successfully completed......................................
2025-05-04 00:48:10,187:INFO:Initializing save_model()
2025-05-04 00:48:10,187:INFO:save_model(model=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), model_name=../FE/automation-data-analysts/public/automl_outputs\automl_1\models\tuned_rf_20250504_004810_1, prep_pipe_=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Trans...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-04 00:48:10,187:INFO:Adding model into prep_pipe
2025-05-04 00:48:10,250:INFO:../FE/automation-data-analysts/public/automl_outputs\automl_1\models\tuned_rf_20250504_004810_1.pkl saved in current working directory
2025-05-04 00:48:10,267:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Trans...
                 RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                                        class_weight={}, criterion='entropy',
                                        max_depth=10, max_features=1.0,
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.001,
                                        min_samples_leaf=2, min_samples_split=7,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=140,
                                        n_jobs=-1, oob_score=False,
                                        random_state=1, verbose=0,
                                        warm_start=False))],
         verbose=False)
2025-05-04 00:48:10,267:INFO:save_model() successfully completed......................................
2025-05-04 00:56:49,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:56:49,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:56:49,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:56:49,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:57:12,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:57:12,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:57:12,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:57:12,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:57:26,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:57:26,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:57:26,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 00:57:26,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:00:47,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:00:47,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:00:47,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:00:47,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:03:35,896:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:03:35,896:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:03:35,896:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:03:35,896:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:03:54,251:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:03:54,251:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:03:54,251:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:03:54,252:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:04:11,066:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:04:11,066:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:04:11,066:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:04:11,066:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:07:03,448:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:07:03,448:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:07:03,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:07:03,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:07:57,960:INFO:PyCaret ClassificationExperiment
2025-05-04 01:07:57,961:INFO:Logging name: automl_bigdata_exp
2025-05-04 01:07:57,961:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-04 01:07:57,961:INFO:version 3.3.2
2025-05-04 01:07:57,961:INFO:Initializing setup()
2025-05-04 01:07:57,961:INFO:self.USI: 6d49
2025-05-04 01:07:57,961:INFO:self._variable_keys: {'fold_shuffle_param', 'html_param', 'X', 'is_multiclass', 'fold_groups_param', 'y_test', 'logging_param', 'pipeline', '_available_plots', 'target_param', 'y', 'gpu_n_jobs_param', 'gpu_param', 'idx', 'USI', 'log_plots_param', 'fold_generator', 'seed', 'exp_id', 'exp_name_log', 'X_test', 'data', '_ml_usecase', 'X_train', 'fix_imbalance', 'y_train', 'n_jobs_param', 'memory'}
2025-05-04 01:07:57,961:INFO:Checking environment
2025-05-04 01:07:57,961:INFO:python_version: 3.10.11
2025-05-04 01:07:57,961:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2025-05-04 01:07:57,961:INFO:machine: AMD64
2025-05-04 01:07:57,986:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-04 01:07:57,990:INFO:Memory: svmem(total=8425017344, available=1040617472, percent=87.6, used=7384399872, free=1040617472)
2025-05-04 01:07:57,990:INFO:Physical Core: 4
2025-05-04 01:07:57,990:INFO:Logical Core: 8
2025-05-04 01:07:57,990:INFO:Checking libraries
2025-05-04 01:07:57,990:INFO:System:
2025-05-04 01:07:57,990:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2025-05-04 01:07:57,990:INFO:executable: c:\LKN\venv\Scripts\python.exe
2025-05-04 01:07:57,990:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-04 01:07:57,990:INFO:PyCaret required dependencies:
2025-05-04 01:07:57,990:INFO:                 pip: 23.0.1
2025-05-04 01:07:57,990:INFO:          setuptools: 65.5.0
2025-05-04 01:07:57,990:INFO:             pycaret: 3.3.2
2025-05-04 01:07:57,990:INFO:             IPython: 8.36.0
2025-05-04 01:07:57,990:INFO:          ipywidgets: 8.1.6
2025-05-04 01:07:57,990:INFO:                tqdm: 4.67.1
2025-05-04 01:07:57,991:INFO:               numpy: 1.26.4
2025-05-04 01:07:57,991:INFO:              pandas: 1.5.3
2025-05-04 01:07:57,991:INFO:              jinja2: 3.1.6
2025-05-04 01:07:57,991:INFO:               scipy: 1.11.4
2025-05-04 01:07:57,991:INFO:              joblib: 1.3.2
2025-05-04 01:07:57,991:INFO:             sklearn: 1.4.2
2025-05-04 01:07:57,991:INFO:                pyod: 2.0.4
2025-05-04 01:07:57,991:INFO:            imblearn: 0.13.0
2025-05-04 01:07:57,991:INFO:   category_encoders: 2.7.0
2025-05-04 01:07:57,991:INFO:            lightgbm: 4.6.0
2025-05-04 01:07:57,991:INFO:               numba: 0.61.0
2025-05-04 01:07:57,991:INFO:            requests: 2.32.3
2025-05-04 01:07:57,992:INFO:          matplotlib: 3.7.5
2025-05-04 01:07:57,992:INFO:          scikitplot: 0.3.7
2025-05-04 01:07:57,992:INFO:         yellowbrick: 1.5
2025-05-04 01:07:57,992:INFO:              plotly: 5.24.1
2025-05-04 01:07:57,992:INFO:    plotly-resampler: Not installed
2025-05-04 01:07:57,992:INFO:             kaleido: 0.2.1
2025-05-04 01:07:57,992:INFO:           schemdraw: 0.15
2025-05-04 01:07:57,992:INFO:         statsmodels: 0.14.4
2025-05-04 01:07:57,992:INFO:              sktime: 0.26.0
2025-05-04 01:07:57,992:INFO:               tbats: 1.1.3
2025-05-04 01:07:57,992:INFO:            pmdarima: 2.0.4
2025-05-04 01:07:57,992:INFO:              psutil: 7.0.0
2025-05-04 01:07:57,992:INFO:          markupsafe: 3.0.2
2025-05-04 01:07:57,992:INFO:             pickle5: Not installed
2025-05-04 01:07:57,992:INFO:         cloudpickle: 2.2.1
2025-05-04 01:07:57,992:INFO:         deprecation: 2.1.0
2025-05-04 01:07:57,992:INFO:              xxhash: 3.5.0
2025-05-04 01:07:57,992:INFO:           wurlitzer: Not installed
2025-05-04 01:07:57,992:INFO:PyCaret optional dependencies:
2025-05-04 01:07:58,004:INFO:                shap: 0.47.2
2025-05-04 01:07:58,004:INFO:           interpret: Not installed
2025-05-04 01:07:58,004:INFO:                umap: Not installed
2025-05-04 01:07:58,004:INFO:     ydata_profiling: 4.16.1
2025-05-04 01:07:58,005:INFO:  explainerdashboard: Not installed
2025-05-04 01:07:58,005:INFO:             autoviz: Not installed
2025-05-04 01:07:58,005:INFO:           fairlearn: Not installed
2025-05-04 01:07:58,005:INFO:          deepchecks: Not installed
2025-05-04 01:07:58,005:INFO:             xgboost: Not installed
2025-05-04 01:07:58,005:INFO:            catboost: Not installed
2025-05-04 01:07:58,005:INFO:              kmodes: Not installed
2025-05-04 01:07:58,005:INFO:             mlxtend: Not installed
2025-05-04 01:07:58,005:INFO:       statsforecast: Not installed
2025-05-04 01:07:58,005:INFO:        tune_sklearn: Not installed
2025-05-04 01:07:58,005:INFO:                 ray: Not installed
2025-05-04 01:07:58,005:INFO:            hyperopt: Not installed
2025-05-04 01:07:58,005:INFO:              optuna: 4.3.0
2025-05-04 01:07:58,005:INFO:               skopt: Not installed
2025-05-04 01:07:58,005:INFO:              mlflow: 2.22.0
2025-05-04 01:07:58,005:INFO:              gradio: Not installed
2025-05-04 01:07:58,005:INFO:             fastapi: 0.115.12
2025-05-04 01:07:58,005:INFO:             uvicorn: 0.34.2
2025-05-04 01:07:58,005:INFO:              m2cgen: Not installed
2025-05-04 01:07:58,005:INFO:           evidently: 0.7.3
2025-05-04 01:07:58,005:INFO:               fugue: Not installed
2025-05-04 01:07:58,006:INFO:           streamlit: Not installed
2025-05-04 01:07:58,006:INFO:             prophet: Not installed
2025-05-04 01:07:58,006:INFO:None
2025-05-04 01:07:58,006:INFO:Set up data.
2025-05-04 01:07:58,015:INFO:Set up folding strategy.
2025-05-04 01:07:58,016:INFO:Set up train/test split.
2025-05-04 01:07:58,023:INFO:Set up index.
2025-05-04 01:07:58,024:INFO:Assigning column types.
2025-05-04 01:07:58,027:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-04 01:07:58,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:07:58,115:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:07:58,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:07:58,208:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:07:58,208:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-04 01:07:58,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:07:58,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:07:58,430:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:07:58,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:07:58,431:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-04 01:07:58,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:07:58,572:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:07:58,845:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:07:58,847:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:07:58,853:INFO:Preparing preprocessing pipeline...
2025-05-04 01:07:58,855:INFO:Set up simple imputation.
2025-05-04 01:07:58,857:INFO:Set up encoding of ordinal features.
2025-05-04 01:07:58,859:INFO:Set up encoding of categorical features.
2025-05-04 01:07:58,860:INFO:Set up column name cleaning.
2025-05-04 01:07:58,922:INFO:Finished creating preprocessing pipeline.
2025-05-04 01:07:58,948:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-05-04 01:07:58,948:INFO:Creating final display dataframe.
2025-05-04 01:07:59,110:INFO:Setup _display_container:                     Description               Value
0                    Session id                   1
1                        Target         Dropped_out
2                   Target type              Binary
3           Original data shape           (249, 17)
4        Transformed data shape            (249, 6)
5   Transformed train set shape            (174, 6)
6    Transformed test set shape             (75, 6)
7               Ignore features                  11
8              Numeric features                   4
9          Categorical features                   1
10     Rows with missing values               38.2%
11                   Preprocess                True
12              Imputation type              simple
13           Numeric imputation                mean
14       Categorical imputation                mode
15     Maximum one-hot encoding                  25
16              Encoding method                None
17               Fold Generator     StratifiedKFold
18                  Fold Number                   5
19                     CPU Jobs                  -1
20                      Use GPU               False
21               Log Experiment        MlflowLogger
22              Experiment Name  automl_bigdata_exp
23                          USI                6d49
2025-05-04 01:07:59,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:07:59,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:07:59,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:07:59,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:07:59,274:INFO:Logging experiment in loggers
2025-05-04 01:07:59,365:INFO:SubProcess save_model() called ==================================
2025-05-04 01:07:59,412:INFO:Initializing save_model()
2025-05-04 01:07:59,413:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\nkluo\AppData\Local\Temp\tmpj1kbi6jz\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-04 01:07:59,413:INFO:Adding model into prep_pipe
2025-05-04 01:07:59,413:WARNING:Only Model saved as it was a pipeline.
2025-05-04 01:07:59,416:INFO:C:\Users\nkluo\AppData\Local\Temp\tmpj1kbi6jz\Transformation Pipeline.pkl saved in current working directory
2025-05-04 01:07:59,440:INFO:Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-05-04 01:07:59,440:INFO:save_model() successfully completed......................................
2025-05-04 01:07:59,606:INFO:SubProcess save_model() end ==================================
2025-05-04 01:07:59,623:INFO:setup() successfully completed in 1.34s...............
2025-05-04 01:07:59,685:INFO:Initializing create_model()
2025-05-04 01:07:59,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205A9DEDE10>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 01:07:59,685:INFO:Checking exceptions
2025-05-04 01:07:59,687:INFO:Importing libraries
2025-05-04 01:07:59,687:INFO:Copying training dataset
2025-05-04 01:07:59,691:INFO:Defining folds
2025-05-04 01:07:59,691:INFO:Declaring metric variables
2025-05-04 01:07:59,691:INFO:Importing untrained model
2025-05-04 01:07:59,692:INFO:Random Forest Classifier Imported successfully
2025-05-04 01:07:59,692:INFO:Starting cross validation
2025-05-04 01:07:59,693:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 01:08:08,262:INFO:Calculating mean and std
2025-05-04 01:08:08,265:INFO:Creating metrics dataframe
2025-05-04 01:08:08,273:INFO:Finalizing model
2025-05-04 01:08:08,601:INFO:Creating Dashboard logs
2025-05-04 01:08:08,602:INFO:Model: Random Forest Classifier
2025-05-04 01:08:08,665:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}
2025-05-04 01:08:08,794:INFO:Initializing predict_model()
2025-05-04 01:08:08,794:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205A9DEDE10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000205AA22F6D0>)
2025-05-04 01:08:08,794:INFO:Checking exceptions
2025-05-04 01:08:08,794:INFO:Preloading libraries
2025-05-04 01:08:09,103:WARNING:c:\LKN\venv\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2025-05-04 01:08:09,439:INFO:Uploading results into container
2025-05-04 01:08:09,440:INFO:Uploading model into container now
2025-05-04 01:08:09,440:INFO:_master_model_container: 11
2025-05-04 01:08:09,440:INFO:_display_container: 8
2025-05-04 01:08:09,440:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False)
2025-05-04 01:08:09,440:INFO:create_model() successfully completed......................................
2025-05-04 01:08:09,636:INFO:Initializing tune_model()
2025-05-04 01:08:09,637:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), fold=5, round=4, n_iter=25, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205A9DEDE10>)
2025-05-04 01:08:09,637:INFO:Checking exceptions
2025-05-04 01:08:09,639:INFO:Copying training dataset
2025-05-04 01:08:09,642:INFO:Checking base model
2025-05-04 01:08:09,642:INFO:Base model : Random Forest Classifier
2025-05-04 01:08:09,642:INFO:Declaring metric variables
2025-05-04 01:08:09,642:INFO:Defining Hyperparameters
2025-05-04 01:08:09,824:INFO:Tuning with n_jobs=-1
2025-05-04 01:08:09,824:INFO:Initializing RandomizedSearchCV
2025-05-04 01:08:30,571:INFO:best_params: {'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': False}
2025-05-04 01:08:30,572:INFO:Hyperparameter search completed
2025-05-04 01:08:30,572:INFO:SubProcess create_model() called ==================================
2025-05-04 01:08:30,575:INFO:Initializing create_model()
2025-05-04 01:08:30,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205A9DEDE10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205A95AC430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 140, 'min_samples_split': 7, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.001, 'max_features': 1.0, 'max_depth': 10, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': False})
2025-05-04 01:08:30,575:INFO:Checking exceptions
2025-05-04 01:08:30,575:INFO:Importing libraries
2025-05-04 01:08:30,576:INFO:Copying training dataset
2025-05-04 01:08:30,590:INFO:Defining folds
2025-05-04 01:08:30,590:INFO:Declaring metric variables
2025-05-04 01:08:30,592:INFO:Importing untrained model
2025-05-04 01:08:30,592:INFO:Declaring custom model
2025-05-04 01:08:30,595:INFO:Random Forest Classifier Imported successfully
2025-05-04 01:08:30,596:INFO:Starting cross validation
2025-05-04 01:08:30,599:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 01:08:31,246:INFO:Calculating mean and std
2025-05-04 01:08:31,246:INFO:Creating metrics dataframe
2025-05-04 01:08:31,250:INFO:Finalizing model
2025-05-04 01:08:31,500:INFO:Uploading results into container
2025-05-04 01:08:31,500:INFO:Uploading model into container now
2025-05-04 01:08:31,501:INFO:_master_model_container: 12
2025-05-04 01:08:31,501:INFO:_display_container: 9
2025-05-04 01:08:31,501:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False)
2025-05-04 01:08:31,501:INFO:create_model() successfully completed......................................
2025-05-04 01:08:31,668:INFO:SubProcess create_model() end ==================================
2025-05-04 01:08:31,668:INFO:choose_better activated
2025-05-04 01:08:31,668:INFO:SubProcess create_model() called ==================================
2025-05-04 01:08:31,669:INFO:Initializing create_model()
2025-05-04 01:08:31,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205A9DEDE10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 01:08:31,669:INFO:Checking exceptions
2025-05-04 01:08:31,671:INFO:Importing libraries
2025-05-04 01:08:31,671:INFO:Copying training dataset
2025-05-04 01:08:31,676:INFO:Defining folds
2025-05-04 01:08:31,676:INFO:Declaring metric variables
2025-05-04 01:08:31,677:INFO:Importing untrained model
2025-05-04 01:08:31,677:INFO:Declaring custom model
2025-05-04 01:08:31,677:INFO:Random Forest Classifier Imported successfully
2025-05-04 01:08:31,678:INFO:Starting cross validation
2025-05-04 01:08:31,679:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 01:08:32,249:INFO:Calculating mean and std
2025-05-04 01:08:32,250:INFO:Creating metrics dataframe
2025-05-04 01:08:32,260:INFO:Finalizing model
2025-05-04 01:08:32,559:INFO:Uploading results into container
2025-05-04 01:08:32,560:INFO:Uploading model into container now
2025-05-04 01:08:32,561:INFO:_master_model_container: 13
2025-05-04 01:08:32,561:INFO:_display_container: 10
2025-05-04 01:08:32,561:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False)
2025-05-04 01:08:32,561:INFO:create_model() successfully completed......................................
2025-05-04 01:08:32,723:INFO:SubProcess create_model() end ==================================
2025-05-04 01:08:32,724:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False) result for AUC is 0.6439
2025-05-04 01:08:32,724:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False) result for AUC is 0.6472
2025-05-04 01:08:32,725:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False) is best model
2025-05-04 01:08:32,726:INFO:choose_better completed
2025-05-04 01:08:32,726:INFO:Creating Dashboard logs
2025-05-04 01:08:32,726:INFO:Model: Random Forest Classifier
2025-05-04 01:08:32,762:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': {}, 'criterion': 'entropy', 'max_depth': 10, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.001, 'min_samples_leaf': 2, 'min_samples_split': 7, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 140, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}
2025-05-04 01:08:32,982:INFO:Initializing predict_model()
2025-05-04 01:08:32,983:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205A9DEDE10>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000205AA22F6D0>)
2025-05-04 01:08:32,983:INFO:Checking exceptions
2025-05-04 01:08:32,983:INFO:Preloading libraries
2025-05-04 01:08:33,702:INFO:_master_model_container: 13
2025-05-04 01:08:33,702:INFO:_display_container: 9
2025-05-04 01:08:33,703:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False)
2025-05-04 01:08:33,703:INFO:tune_model() successfully completed......................................
2025-05-04 01:08:33,936:INFO:gpu_param set to False
2025-05-04 01:08:34,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:08:34,027:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:08:34,114:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:08:34,114:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:08:34,116:INFO:Initializing predict_model()
2025-05-04 01:08:34,116:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205A9DEDE10>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000205A21D2680>)
2025-05-04 01:08:34,116:INFO:Checking exceptions
2025-05-04 01:08:34,117:INFO:Preloading libraries
2025-05-04 01:08:34,506:INFO:Initializing plot_model()
2025-05-04 01:08:34,506:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205A9DEDE10>, system=True)
2025-05-04 01:08:34,507:INFO:Checking exceptions
2025-05-04 01:08:34,552:INFO:Preloading libraries
2025-05-04 01:08:34,568:INFO:Copying training dataset
2025-05-04 01:08:34,569:INFO:Plot type: feature
2025-05-04 01:08:34,570:WARNING:No coef_ found. Trying feature_importances_
2025-05-04 01:08:34,679:WARNING:c:\LKN\venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1845: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  plt.figure(figsize=(8, 5 * (n // 10)), dpi=_base_dpi * scale)

2025-05-04 01:08:34,960:INFO:Saving 'Feature Importance.png'
2025-05-04 01:08:35,128:INFO:Visual Rendered Successfully
2025-05-04 01:08:35,302:INFO:plot_model() successfully completed......................................
2025-05-04 01:08:35,348:INFO:Initializing plot_model()
2025-05-04 01:08:35,348:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205A9DEDE10>, system=True)
2025-05-04 01:08:35,348:INFO:Checking exceptions
2025-05-04 01:08:35,395:INFO:Preloading libraries
2025-05-04 01:08:35,411:INFO:Copying training dataset
2025-05-04 01:08:35,411:INFO:Plot type: auc
2025-05-04 01:08:35,491:WARNING:c:\LKN\venv\lib\site-packages\yellowbrick\base.py:111: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  self._fig = plt.gcf()

2025-05-04 01:08:35,622:INFO:Fitting Model
2025-05-04 01:08:35,623:WARNING:c:\LKN\venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-05-04 01:08:35,624:INFO:Scoring test/hold-out set
2025-05-04 01:08:35,736:INFO:Saving 'AUC.png'
2025-05-04 01:08:35,947:INFO:Visual Rendered Successfully
2025-05-04 01:08:36,129:INFO:plot_model() successfully completed......................................
2025-05-04 01:08:36,162:INFO:Initializing plot_model()
2025-05-04 01:08:36,162:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205A9DEDE10>, system=True)
2025-05-04 01:08:36,162:INFO:Checking exceptions
2025-05-04 01:08:36,197:INFO:Preloading libraries
2025-05-04 01:08:36,208:INFO:Copying training dataset
2025-05-04 01:08:36,208:INFO:Plot type: confusion_matrix
2025-05-04 01:08:36,284:WARNING:c:\LKN\venv\lib\site-packages\yellowbrick\base.py:111: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  self._fig = plt.gcf()

2025-05-04 01:08:36,389:INFO:Fitting Model
2025-05-04 01:08:36,389:WARNING:c:\LKN\venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-05-04 01:08:36,389:INFO:Scoring test/hold-out set
2025-05-04 01:08:36,478:INFO:Saving 'Confusion Matrix.png'
2025-05-04 01:08:36,616:INFO:Visual Rendered Successfully
2025-05-04 01:08:36,806:INFO:plot_model() successfully completed......................................
2025-05-04 01:08:36,835:INFO:Initializing plot_model()
2025-05-04 01:08:36,835:INFO:plot_model(plot=pr, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205A9DEDE10>, system=True)
2025-05-04 01:08:36,835:INFO:Checking exceptions
2025-05-04 01:08:36,870:INFO:Preloading libraries
2025-05-04 01:08:36,879:INFO:Copying training dataset
2025-05-04 01:08:36,880:INFO:Plot type: pr
2025-05-04 01:08:36,982:WARNING:c:\LKN\venv\lib\site-packages\yellowbrick\base.py:111: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  self._fig = plt.gcf()

2025-05-04 01:08:37,147:INFO:Fitting Model
2025-05-04 01:08:37,148:WARNING:c:\LKN\venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-05-04 01:08:37,148:INFO:Scoring test/hold-out set
2025-05-04 01:08:37,303:INFO:Saving 'Precision Recall.png'
2025-05-04 01:08:37,470:INFO:Visual Rendered Successfully
2025-05-04 01:08:37,658:INFO:plot_model() successfully completed......................................
2025-05-04 01:08:37,690:INFO:Initializing plot_model()
2025-05-04 01:08:37,690:INFO:plot_model(plot=class_report, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205A9DEDE10>, system=True)
2025-05-04 01:08:37,690:INFO:Checking exceptions
2025-05-04 01:08:37,733:INFO:Preloading libraries
2025-05-04 01:08:37,744:INFO:Copying training dataset
2025-05-04 01:08:37,744:INFO:Plot type: class_report
2025-05-04 01:08:37,824:WARNING:c:\LKN\venv\lib\site-packages\yellowbrick\base.py:111: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  self._fig = plt.gcf()

2025-05-04 01:08:37,929:INFO:Fitting Model
2025-05-04 01:08:37,929:WARNING:c:\LKN\venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-05-04 01:08:37,929:INFO:Scoring test/hold-out set
2025-05-04 01:08:38,068:INFO:Saving 'Class Report.png'
2025-05-04 01:08:38,260:INFO:Visual Rendered Successfully
2025-05-04 01:08:38,452:INFO:plot_model() successfully completed......................................
2025-05-04 01:08:38,537:INFO:Initializing save_model()
2025-05-04 01:08:38,537:INFO:save_model(model=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), model_name=../FE/automation-data-analysts/public/automl_outputs\automl_1\models\tuned_rf_20250504_010838_1, prep_pipe_=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Trans...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-04 01:08:38,537:INFO:Adding model into prep_pipe
2025-05-04 01:08:38,600:INFO:../FE/automation-data-analysts/public/automl_outputs\automl_1\models\tuned_rf_20250504_010838_1.pkl saved in current working directory
2025-05-04 01:08:38,627:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Trans...
                 RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                                        class_weight={}, criterion='entropy',
                                        max_depth=10, max_features=1.0,
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.001,
                                        min_samples_leaf=2, min_samples_split=7,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=140,
                                        n_jobs=-1, oob_score=False,
                                        random_state=1, verbose=0,
                                        warm_start=False))],
         verbose=False)
2025-05-04 01:08:38,627:INFO:save_model() successfully completed......................................
2025-05-04 01:10:48,749:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:10:48,749:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:10:48,749:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:10:48,749:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:11:08,577:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:11:08,577:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:11:08,577:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:11:08,577:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:11:50,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:11:50,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:11:50,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:11:50,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:13:08,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:13:08,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:13:08,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:13:08,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:13:33,892:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:13:33,892:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:13:33,892:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:13:33,892:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:13:53,548:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:13:53,549:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:13:53,549:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:13:53,549:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-04 01:14:27,960:INFO:PyCaret ClassificationExperiment
2025-05-04 01:14:27,960:INFO:Logging name: automl_bigdata_exp
2025-05-04 01:14:27,960:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-04 01:14:27,960:INFO:version 3.3.2
2025-05-04 01:14:27,960:INFO:Initializing setup()
2025-05-04 01:14:27,960:INFO:self.USI: 4eb1
2025-05-04 01:14:27,960:INFO:self._variable_keys: {'idx', 'X_train', 'html_param', 'n_jobs_param', 'fold_shuffle_param', 'data', 'gpu_n_jobs_param', 'is_multiclass', 'memory', 'fold_generator', 'exp_name_log', 'pipeline', 'log_plots_param', 'fold_groups_param', 'y_train', 'USI', 'target_param', 'exp_id', 'gpu_param', '_ml_usecase', 'y_test', 'X', 'fix_imbalance', '_available_plots', 'seed', 'logging_param', 'X_test', 'y'}
2025-05-04 01:14:27,960:INFO:Checking environment
2025-05-04 01:14:27,961:INFO:python_version: 3.10.11
2025-05-04 01:14:27,961:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2025-05-04 01:14:27,961:INFO:machine: AMD64
2025-05-04 01:14:27,976:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-04 01:14:27,980:INFO:Memory: svmem(total=8425017344, available=1038045184, percent=87.7, used=7386972160, free=1038045184)
2025-05-04 01:14:27,980:INFO:Physical Core: 4
2025-05-04 01:14:27,980:INFO:Logical Core: 8
2025-05-04 01:14:27,980:INFO:Checking libraries
2025-05-04 01:14:27,980:INFO:System:
2025-05-04 01:14:27,980:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2025-05-04 01:14:27,980:INFO:executable: c:\LKN\venv\Scripts\python.exe
2025-05-04 01:14:27,980:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-04 01:14:27,980:INFO:PyCaret required dependencies:
2025-05-04 01:14:27,980:INFO:                 pip: 23.0.1
2025-05-04 01:14:27,981:INFO:          setuptools: 65.5.0
2025-05-04 01:14:27,981:INFO:             pycaret: 3.3.2
2025-05-04 01:14:27,981:INFO:             IPython: 8.36.0
2025-05-04 01:14:27,981:INFO:          ipywidgets: 8.1.6
2025-05-04 01:14:27,981:INFO:                tqdm: 4.67.1
2025-05-04 01:14:27,981:INFO:               numpy: 1.26.4
2025-05-04 01:14:27,981:INFO:              pandas: 1.5.3
2025-05-04 01:14:27,981:INFO:              jinja2: 3.1.6
2025-05-04 01:14:27,981:INFO:               scipy: 1.11.4
2025-05-04 01:14:27,981:INFO:              joblib: 1.3.2
2025-05-04 01:14:27,981:INFO:             sklearn: 1.4.2
2025-05-04 01:14:27,981:INFO:                pyod: 2.0.4
2025-05-04 01:14:27,982:INFO:            imblearn: 0.13.0
2025-05-04 01:14:27,982:INFO:   category_encoders: 2.7.0
2025-05-04 01:14:27,982:INFO:            lightgbm: 4.6.0
2025-05-04 01:14:27,982:INFO:               numba: 0.61.0
2025-05-04 01:14:27,982:INFO:            requests: 2.32.3
2025-05-04 01:14:27,982:INFO:          matplotlib: 3.7.5
2025-05-04 01:14:27,982:INFO:          scikitplot: 0.3.7
2025-05-04 01:14:27,983:INFO:         yellowbrick: 1.5
2025-05-04 01:14:27,983:INFO:              plotly: 5.24.1
2025-05-04 01:14:27,983:INFO:    plotly-resampler: Not installed
2025-05-04 01:14:27,983:INFO:             kaleido: 0.2.1
2025-05-04 01:14:27,983:INFO:           schemdraw: 0.15
2025-05-04 01:14:27,983:INFO:         statsmodels: 0.14.4
2025-05-04 01:14:27,983:INFO:              sktime: 0.26.0
2025-05-04 01:14:27,983:INFO:               tbats: 1.1.3
2025-05-04 01:14:27,983:INFO:            pmdarima: 2.0.4
2025-05-04 01:14:27,983:INFO:              psutil: 7.0.0
2025-05-04 01:14:27,983:INFO:          markupsafe: 3.0.2
2025-05-04 01:14:27,983:INFO:             pickle5: Not installed
2025-05-04 01:14:27,983:INFO:         cloudpickle: 2.2.1
2025-05-04 01:14:27,983:INFO:         deprecation: 2.1.0
2025-05-04 01:14:27,983:INFO:              xxhash: 3.5.0
2025-05-04 01:14:27,983:INFO:           wurlitzer: Not installed
2025-05-04 01:14:27,984:INFO:PyCaret optional dependencies:
2025-05-04 01:14:27,996:INFO:                shap: 0.47.2
2025-05-04 01:14:27,996:INFO:           interpret: Not installed
2025-05-04 01:14:27,996:INFO:                umap: Not installed
2025-05-04 01:14:27,996:INFO:     ydata_profiling: 4.16.1
2025-05-04 01:14:27,996:INFO:  explainerdashboard: Not installed
2025-05-04 01:14:27,996:INFO:             autoviz: Not installed
2025-05-04 01:14:27,996:INFO:           fairlearn: Not installed
2025-05-04 01:14:27,996:INFO:          deepchecks: Not installed
2025-05-04 01:14:27,996:INFO:             xgboost: Not installed
2025-05-04 01:14:27,996:INFO:            catboost: Not installed
2025-05-04 01:14:27,996:INFO:              kmodes: Not installed
2025-05-04 01:14:27,996:INFO:             mlxtend: Not installed
2025-05-04 01:14:27,996:INFO:       statsforecast: Not installed
2025-05-04 01:14:27,996:INFO:        tune_sklearn: Not installed
2025-05-04 01:14:27,996:INFO:                 ray: Not installed
2025-05-04 01:14:27,996:INFO:            hyperopt: Not installed
2025-05-04 01:14:27,996:INFO:              optuna: 4.3.0
2025-05-04 01:14:27,996:INFO:               skopt: Not installed
2025-05-04 01:14:27,996:INFO:              mlflow: 2.22.0
2025-05-04 01:14:27,996:INFO:              gradio: Not installed
2025-05-04 01:14:27,996:INFO:             fastapi: 0.115.12
2025-05-04 01:14:27,996:INFO:             uvicorn: 0.34.2
2025-05-04 01:14:27,996:INFO:              m2cgen: Not installed
2025-05-04 01:14:27,996:INFO:           evidently: 0.7.3
2025-05-04 01:14:27,998:INFO:               fugue: Not installed
2025-05-04 01:14:27,998:INFO:           streamlit: Not installed
2025-05-04 01:14:27,998:INFO:             prophet: Not installed
2025-05-04 01:14:27,998:INFO:None
2025-05-04 01:14:27,998:INFO:Set up data.
2025-05-04 01:14:28,006:INFO:Set up folding strategy.
2025-05-04 01:14:28,006:INFO:Set up train/test split.
2025-05-04 01:14:28,013:INFO:Set up index.
2025-05-04 01:14:28,013:INFO:Assigning column types.
2025-05-04 01:14:28,018:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-04 01:14:28,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:14:28,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:14:28,193:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:14:28,194:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:14:28,194:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-04 01:14:28,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:14:28,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:14:28,456:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:14:28,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:14:28,457:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-04 01:14:28,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:14:28,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:14:28,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:14:28,803:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:14:28,807:INFO:Preparing preprocessing pipeline...
2025-05-04 01:14:28,808:INFO:Set up simple imputation.
2025-05-04 01:14:28,812:INFO:Set up encoding of ordinal features.
2025-05-04 01:14:28,814:INFO:Set up encoding of categorical features.
2025-05-04 01:14:28,815:INFO:Set up column name cleaning.
2025-05-04 01:14:28,874:INFO:Finished creating preprocessing pipeline.
2025-05-04 01:14:28,901:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-05-04 01:14:28,901:INFO:Creating final display dataframe.
2025-05-04 01:14:29,054:INFO:Setup _display_container:                     Description               Value
0                    Session id                   1
1                        Target         Dropped_out
2                   Target type              Binary
3           Original data shape           (249, 17)
4        Transformed data shape            (249, 6)
5   Transformed train set shape            (174, 6)
6    Transformed test set shape             (75, 6)
7               Ignore features                  11
8              Numeric features                   4
9          Categorical features                   1
10     Rows with missing values               38.2%
11                   Preprocess                True
12              Imputation type              simple
13           Numeric imputation                mean
14       Categorical imputation                mode
15     Maximum one-hot encoding                  25
16              Encoding method                None
17               Fold Generator     StratifiedKFold
18                  Fold Number                   5
19                     CPU Jobs                  -1
20                      Use GPU               False
21               Log Experiment        MlflowLogger
22              Experiment Name  automl_bigdata_exp
23                          USI                4eb1
2025-05-04 01:14:29,138:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:14:29,138:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:14:29,224:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:14:29,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:14:29,225:INFO:Logging experiment in loggers
2025-05-04 01:14:29,309:INFO:SubProcess save_model() called ==================================
2025-05-04 01:14:29,352:INFO:Initializing save_model()
2025-05-04 01:14:29,352:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\nkluo\AppData\Local\Temp\tmpwvrvd4xv\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-04 01:14:29,353:INFO:Adding model into prep_pipe
2025-05-04 01:14:29,353:WARNING:Only Model saved as it was a pipeline.
2025-05-04 01:14:29,356:INFO:C:\Users\nkluo\AppData\Local\Temp\tmpwvrvd4xv\Transformation Pipeline.pkl saved in current working directory
2025-05-04 01:14:29,379:INFO:Pipeline(memory=FastMemory(location=C:\Users\nkluo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-05-04 01:14:29,380:INFO:save_model() successfully completed......................................
2025-05-04 01:14:29,547:INFO:SubProcess save_model() end ==================================
2025-05-04 01:14:29,564:INFO:setup() successfully completed in 1.3s...............
2025-05-04 01:14:29,627:INFO:Initializing create_model()
2025-05-04 01:14:29,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182BE101ED0>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 01:14:29,628:INFO:Checking exceptions
2025-05-04 01:14:29,630:INFO:Importing libraries
2025-05-04 01:14:29,630:INFO:Copying training dataset
2025-05-04 01:14:29,637:INFO:Defining folds
2025-05-04 01:14:29,637:INFO:Declaring metric variables
2025-05-04 01:14:29,637:INFO:Importing untrained model
2025-05-04 01:14:29,638:INFO:Random Forest Classifier Imported successfully
2025-05-04 01:14:29,638:INFO:Starting cross validation
2025-05-04 01:14:29,639:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 01:14:40,989:INFO:Calculating mean and std
2025-05-04 01:14:40,991:INFO:Creating metrics dataframe
2025-05-04 01:14:40,995:INFO:Finalizing model
2025-05-04 01:14:41,227:INFO:Creating Dashboard logs
2025-05-04 01:14:41,227:INFO:Model: Random Forest Classifier
2025-05-04 01:14:41,261:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}
2025-05-04 01:14:41,395:INFO:Initializing predict_model()
2025-05-04 01:14:41,395:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182BE101ED0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000182BE543640>)
2025-05-04 01:14:41,395:INFO:Checking exceptions
2025-05-04 01:14:41,395:INFO:Preloading libraries
2025-05-04 01:14:41,709:WARNING:c:\LKN\venv\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2025-05-04 01:14:41,980:INFO:Uploading results into container
2025-05-04 01:14:41,981:INFO:Uploading model into container now
2025-05-04 01:14:41,982:INFO:_master_model_container: 11
2025-05-04 01:14:41,982:INFO:_display_container: 8
2025-05-04 01:14:41,982:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False)
2025-05-04 01:14:41,982:INFO:create_model() successfully completed......................................
2025-05-04 01:14:42,172:INFO:Initializing tune_model()
2025-05-04 01:14:42,172:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), fold=5, round=4, n_iter=25, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182BE101ED0>)
2025-05-04 01:14:42,172:INFO:Checking exceptions
2025-05-04 01:14:42,175:INFO:Copying training dataset
2025-05-04 01:14:42,180:INFO:Checking base model
2025-05-04 01:14:42,181:INFO:Base model : Random Forest Classifier
2025-05-04 01:14:42,183:INFO:Declaring metric variables
2025-05-04 01:14:42,183:INFO:Defining Hyperparameters
2025-05-04 01:14:42,361:INFO:Tuning with n_jobs=-1
2025-05-04 01:14:42,361:INFO:Initializing RandomizedSearchCV
2025-05-04 01:15:07,750:INFO:best_params: {'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': False}
2025-05-04 01:15:07,750:INFO:Hyperparameter search completed
2025-05-04 01:15:07,751:INFO:SubProcess create_model() called ==================================
2025-05-04 01:15:07,753:INFO:Initializing create_model()
2025-05-04 01:15:07,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182BE101ED0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000182BE5721A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 140, 'min_samples_split': 7, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.001, 'max_features': 1.0, 'max_depth': 10, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': False})
2025-05-04 01:15:07,753:INFO:Checking exceptions
2025-05-04 01:15:07,754:INFO:Importing libraries
2025-05-04 01:15:07,754:INFO:Copying training dataset
2025-05-04 01:15:07,765:INFO:Defining folds
2025-05-04 01:15:07,766:INFO:Declaring metric variables
2025-05-04 01:15:07,766:INFO:Importing untrained model
2025-05-04 01:15:07,766:INFO:Declaring custom model
2025-05-04 01:15:07,767:INFO:Random Forest Classifier Imported successfully
2025-05-04 01:15:07,768:INFO:Starting cross validation
2025-05-04 01:15:07,770:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 01:15:09,030:INFO:Calculating mean and std
2025-05-04 01:15:09,030:INFO:Creating metrics dataframe
2025-05-04 01:15:09,039:INFO:Finalizing model
2025-05-04 01:15:09,532:INFO:Uploading results into container
2025-05-04 01:15:09,532:INFO:Uploading model into container now
2025-05-04 01:15:09,533:INFO:_master_model_container: 12
2025-05-04 01:15:09,533:INFO:_display_container: 9
2025-05-04 01:15:09,533:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False)
2025-05-04 01:15:09,534:INFO:create_model() successfully completed......................................
2025-05-04 01:15:09,749:INFO:SubProcess create_model() end ==================================
2025-05-04 01:15:09,749:INFO:choose_better activated
2025-05-04 01:15:09,749:INFO:SubProcess create_model() called ==================================
2025-05-04 01:15:09,749:INFO:Initializing create_model()
2025-05-04 01:15:09,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182BE101ED0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-04 01:15:09,749:INFO:Checking exceptions
2025-05-04 01:15:09,749:INFO:Importing libraries
2025-05-04 01:15:09,749:INFO:Copying training dataset
2025-05-04 01:15:09,749:INFO:Defining folds
2025-05-04 01:15:09,749:INFO:Declaring metric variables
2025-05-04 01:15:09,749:INFO:Importing untrained model
2025-05-04 01:15:09,749:INFO:Declaring custom model
2025-05-04 01:15:09,749:INFO:Random Forest Classifier Imported successfully
2025-05-04 01:15:09,749:INFO:Starting cross validation
2025-05-04 01:15:09,749:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-04 01:15:10,378:INFO:Calculating mean and std
2025-05-04 01:15:10,379:INFO:Creating metrics dataframe
2025-05-04 01:15:10,379:INFO:Finalizing model
2025-05-04 01:15:10,648:INFO:Uploading results into container
2025-05-04 01:15:10,648:INFO:Uploading model into container now
2025-05-04 01:15:10,648:INFO:_master_model_container: 13
2025-05-04 01:15:10,648:INFO:_display_container: 10
2025-05-04 01:15:10,648:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False)
2025-05-04 01:15:10,648:INFO:create_model() successfully completed......................................
2025-05-04 01:15:10,823:INFO:SubProcess create_model() end ==================================
2025-05-04 01:15:10,823:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False) result for AUC is 0.6439
2025-05-04 01:15:10,829:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False) result for AUC is 0.6472
2025-05-04 01:15:10,829:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False) is best model
2025-05-04 01:15:10,829:INFO:choose_better completed
2025-05-04 01:15:10,829:INFO:Creating Dashboard logs
2025-05-04 01:15:10,829:INFO:Model: Random Forest Classifier
2025-05-04 01:15:10,855:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': {}, 'criterion': 'entropy', 'max_depth': 10, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.001, 'min_samples_leaf': 2, 'min_samples_split': 7, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 140, 'n_jobs': -1, 'oob_score': False, 'random_state': 1, 'verbose': 0, 'warm_start': False}
2025-05-04 01:15:10,991:INFO:Initializing predict_model()
2025-05-04 01:15:10,991:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182BE101ED0>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000182BE543640>)
2025-05-04 01:15:10,991:INFO:Checking exceptions
2025-05-04 01:15:10,991:INFO:Preloading libraries
2025-05-04 01:15:11,648:INFO:_master_model_container: 13
2025-05-04 01:15:11,648:INFO:_display_container: 9
2025-05-04 01:15:11,648:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False)
2025-05-04 01:15:11,648:INFO:tune_model() successfully completed......................................
2025-05-04 01:15:11,886:INFO:gpu_param set to False
2025-05-04 01:15:11,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:15:11,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:15:12,074:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:15:12,075:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-04 01:15:12,075:INFO:Initializing predict_model()
2025-05-04 01:15:12,075:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182BE101ED0>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000182B652E680>)
2025-05-04 01:15:12,075:INFO:Checking exceptions
2025-05-04 01:15:12,075:INFO:Preloading libraries
2025-05-04 01:15:12,491:INFO:Initializing plot_model()
2025-05-04 01:15:12,491:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182BE101ED0>, system=True)
2025-05-04 01:15:12,491:INFO:Checking exceptions
2025-05-04 01:15:12,539:INFO:Preloading libraries
2025-05-04 01:15:12,548:INFO:Copying training dataset
2025-05-04 01:15:12,548:INFO:Plot type: feature
2025-05-04 01:15:12,550:WARNING:No coef_ found. Trying feature_importances_
2025-05-04 01:15:12,648:WARNING:c:\LKN\venv\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1845: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  plt.figure(figsize=(8, 5 * (n // 10)), dpi=_base_dpi * scale)

2025-05-04 01:15:12,900:INFO:Saving 'Feature Importance.png'
2025-05-04 01:15:13,059:INFO:Visual Rendered Successfully
2025-05-04 01:15:13,304:INFO:plot_model() successfully completed......................................
2025-05-04 01:15:13,375:INFO:Initializing plot_model()
2025-05-04 01:15:13,375:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182BE101ED0>, system=True)
2025-05-04 01:15:13,375:INFO:Checking exceptions
2025-05-04 01:15:13,443:INFO:Preloading libraries
2025-05-04 01:15:13,465:INFO:Copying training dataset
2025-05-04 01:15:13,465:INFO:Plot type: auc
2025-05-04 01:15:13,580:WARNING:c:\LKN\venv\lib\site-packages\yellowbrick\base.py:111: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  self._fig = plt.gcf()

2025-05-04 01:15:13,704:INFO:Fitting Model
2025-05-04 01:15:13,706:WARNING:c:\LKN\venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-05-04 01:15:13,706:INFO:Scoring test/hold-out set
2025-05-04 01:15:13,823:INFO:Saving 'AUC.png'
2025-05-04 01:15:14,039:INFO:Visual Rendered Successfully
2025-05-04 01:15:14,233:INFO:plot_model() successfully completed......................................
2025-05-04 01:15:14,262:INFO:Initializing plot_model()
2025-05-04 01:15:14,262:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182BE101ED0>, system=True)
2025-05-04 01:15:14,262:INFO:Checking exceptions
2025-05-04 01:15:14,306:INFO:Preloading libraries
2025-05-04 01:15:14,315:INFO:Copying training dataset
2025-05-04 01:15:14,315:INFO:Plot type: confusion_matrix
2025-05-04 01:15:14,411:WARNING:c:\LKN\venv\lib\site-packages\yellowbrick\base.py:111: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  self._fig = plt.gcf()

2025-05-04 01:15:14,525:INFO:Fitting Model
2025-05-04 01:15:14,525:WARNING:c:\LKN\venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-05-04 01:15:14,525:INFO:Scoring test/hold-out set
2025-05-04 01:15:14,644:INFO:Saving 'Confusion Matrix.png'
2025-05-04 01:15:14,764:INFO:Visual Rendered Successfully
2025-05-04 01:15:14,961:INFO:plot_model() successfully completed......................................
2025-05-04 01:15:14,987:INFO:Initializing plot_model()
2025-05-04 01:15:14,987:INFO:plot_model(plot=pr, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182BE101ED0>, system=True)
2025-05-04 01:15:14,987:INFO:Checking exceptions
2025-05-04 01:15:15,039:INFO:Preloading libraries
2025-05-04 01:15:15,052:INFO:Copying training dataset
2025-05-04 01:15:15,052:INFO:Plot type: pr
2025-05-04 01:15:15,140:WARNING:c:\LKN\venv\lib\site-packages\yellowbrick\base.py:111: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  self._fig = plt.gcf()

2025-05-04 01:15:15,251:INFO:Fitting Model
2025-05-04 01:15:15,251:WARNING:c:\LKN\venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-05-04 01:15:15,251:INFO:Scoring test/hold-out set
2025-05-04 01:15:15,371:INFO:Saving 'Precision Recall.png'
2025-05-04 01:15:15,645:INFO:Visual Rendered Successfully
2025-05-04 01:15:15,840:INFO:plot_model() successfully completed......................................
2025-05-04 01:15:15,879:INFO:Initializing plot_model()
2025-05-04 01:15:15,879:INFO:plot_model(plot=class_report, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000182BE101ED0>, system=True)
2025-05-04 01:15:15,879:INFO:Checking exceptions
2025-05-04 01:15:15,987:INFO:Preloading libraries
2025-05-04 01:15:16,005:INFO:Copying training dataset
2025-05-04 01:15:16,005:INFO:Plot type: class_report
2025-05-04 01:15:16,121:WARNING:c:\LKN\venv\lib\site-packages\yellowbrick\base.py:111: UserWarning: Starting a Matplotlib GUI outside of the main thread will likely fail.
  self._fig = plt.gcf()

2025-05-04 01:15:16,374:INFO:Fitting Model
2025-05-04 01:15:16,374:WARNING:c:\LKN\venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-05-04 01:15:16,374:INFO:Scoring test/hold-out set
2025-05-04 01:15:16,546:INFO:Saving 'Class Report.png'
2025-05-04 01:15:16,736:INFO:Visual Rendered Successfully
2025-05-04 01:15:16,924:INFO:plot_model() successfully completed......................................
2025-05-04 01:15:17,008:INFO:Initializing save_model()
2025-05-04 01:15:17,008:INFO:save_model(model=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=10, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=140, n_jobs=-1,
                       oob_score=False, random_state=1, verbose=0,
                       warm_start=False), model_name=../FE/automation-data-analysts/public/automl_outputs\automl_1\models\tuned_rf_20250504_011516_1, prep_pipe_=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Trans...
                                    transformer=OrdinalEncoder(cols=['Child_Gender'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'Child_Gender',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': Female    0
Male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-04 01:15:17,008:INFO:Adding model into prep_pipe
2025-05-04 01:15:17,081:INFO:../FE/automation-data-analysts/public/automl_outputs\automl_1\models\tuned_rf_20250504_011516_1.pkl saved in current working directory
2025-05-04 01:15:17,101:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Lack_of_School_Material',
                                             'Lack _of _School_Fees',
                                             'Job_opportunity', 'Pregnancy'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Trans...
                 RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                                        class_weight={}, criterion='entropy',
                                        max_depth=10, max_features=1.0,
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.001,
                                        min_samples_leaf=2, min_samples_split=7,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=140,
                                        n_jobs=-1, oob_score=False,
                                        random_state=1, verbose=0,
                                        warm_start=False))],
         verbose=False)
2025-05-04 01:15:17,105:INFO:save_model() successfully completed......................................
